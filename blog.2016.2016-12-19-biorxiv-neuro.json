{"version":1,"kind":"Notebook","sha256":"ec35de57632ff79550722f236f3d65d457d5cee4f742bac397cb8693df9e549c","slug":"blog.2016.2016-12-19-biorxiv-neuro","location":"/blog/2016/2016-12-19-biorxiv_neuro.ipynb","dependencies":[],"frontmatter":{"title":"The bleeding edge of publishing, Scraping publication amounts at biorxiv","tags":["python","open science","visualizations","web scraping","preprints"],"date":"2016-12-19","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"authors":[{"id":"chris","nameParsed":{"literal":"Chris Holdgraf","given":"Chris","family":"Holdgraf"},"name":"Chris Holdgraf","orcid":"0000-0002-2391-0678","affiliations":["affiliations-myst-generated-uid-0","affiliations-myst-generated-uid-1"],"twitter":"choldgraf","github":"choldgraf","url":"https://chrisholdgraf.com"}],"github":"https://github.com/choldgraf/choldgraf.github.io","affiliations":[{"name":"2i2c","url":"https://2i2c.org","id":"affiliations-myst-generated-uid-0"},{"name":"Project Jupyter","url":"https://jupyter.org","id":"affiliations-myst-generated-uid-1"}],"abbreviations":{"LF":"The Linux Foundation","JF":"The Jupyter Foundation","JEC":"Jupyter Executive Council","JFB":"The Jupyter Foundation Board","SSC":"Software Steering Council","OSPO":"Open Source Program Office"},"numbering":{"title":{"offset":2}},"edit_url":"https://github.com/choldgraf/choldgraf.github.io/blob/main/blog/2016/2016-12-19-biorxiv_neuro.ipynb","exports":[{"format":"ipynb","filename":"2016-12-19-biorxiv_neuro.ipynb","url":"/build/2016-12-19-biorxiv_n-01f0e54fb4bf00577b4487de93c322a2.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Per a recent request somebody posted on Twitter, I thought it’d be fun to write a quick scraper for the ","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"KP5i88RdDw"},{"type":"link","url":"http://biorxiv.org/","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"biorxiv","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"byzGNMPLDv"}],"urlSource":"http://biorxiv.org/","key":"EmhwLtGajs"},{"type":"text","value":", an excellent new tool for posting pre-prints of articles before they’re locked down with a publisher embargo.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"cxIZxMUOML"}],"key":"zPsPjIZ8Xn"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"A big benefit of open science is the ability to use modern technologies (like web scraping) to make new use of data that would originally be unavailable to the public. One simple example of this is information and metadata about published articles. While we’re not going to dive too deeply here, maybe this will serve as inspiration for somebody else interested in scraping the web.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"Aa2jJ5oxLv"}],"key":"MAKGqV2kA2"},{"type":"paragraph","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"First we’ll do a few imports. We’ll rely heavily on the ","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"U3Ytym8tcS"},{"type":"inlineCode","value":"requests","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"fDwApeW2xv"},{"type":"text","value":" and ","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"y40stXK5hv"},{"type":"inlineCode","value":"BeautifulSoup","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"g2TSWpGsdF"},{"type":"text","value":" packages, which together make an excellent one-two punch for doing web scraping. We coud use something like ","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"gl7EmCBo3v"},{"type":"inlineCode","value":"scrapy","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"q38ME2YnJJ"},{"type":"text","value":", but that seems a little overkill for this small project.","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"TB9aiqERHV"}],"key":"hcIOSgsQAM"}],"key":"qFezJ6ZtRT"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"import requests\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom bs4 import BeautifulSoup as bs\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n%matplotlib inline","key":"P5yc4PX38Y"},{"type":"output","id":"QwSBMkCiDa-gEBgxbgm1A","data":[],"key":"L0Sf41n1Jy"}],"key":"xismZuiiHv"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"From a quick look at the biorxiv we can see that its search API works in a pretty simple manner. I tried typing in a simple search query and got something like this:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jviA9c6Esw"}],"key":"NcSv4EwR1X"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"inlineCode","value":"http://biorxiv.org/search/neuroscience%20numresults%3A100%20sort%3Arelevance-rank","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"N9tUrj9eeW"}],"key":"W31ux4NsBa"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Here we can see that the term you search for comes just after ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zWMc8v2zbC"},{"type":"inlineCode","value":"/search/","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ySoceRFghr"},{"type":"text","value":", and parameters for the search, like ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"w8Ks775Oim"},{"type":"inlineCode","value":"numresults","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KourvBnhkd"},{"type":"text","value":". The keyword/value pairs are separated by a ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"pk1ayNSZ3z"},{"type":"inlineCode","value":"%3A","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nv4XitSYuq"},{"type":"text","value":" character, which corresponds to ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"tbZTFplffx"},{"type":"inlineCode","value":":","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MJoX1wmy1a"},{"type":"text","value":" (see ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hjKO9UImfb"},{"type":"link","url":"http://www.degraeve.com/reference/urlencoding.php","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"this site","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Z0LPanaHQ1"}],"urlSource":"http://www.degraeve.com/reference/urlencoding.php","key":"hs5Tye7k9y"},{"type":"text","value":" for a reference of url encoding characters), and these key/value pairs are separated by ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lOqlO0bLrd"},{"type":"inlineCode","value":"%20","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"X0v8IxoKDH"},{"type":"text","value":", which corresponds to a space.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"us4L3pTBPV"}],"key":"FHclOe1eOq"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"So, let’s do a simple scrape and see what the results look like. We’ll query the biorxiv API to see what kind of structure the result will have.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"aH45cFiZgx"}],"key":"Lyp7AKBTg8"}],"key":"t0uu903lh4"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"n_results = 20\nurl = \"http://biorxiv.org/search/neuroscience%20numresults%3A{}\".format(\n    n_results)\nresp = requests.post(url)\n\n# I'm not going to print this because it messes up the HTML rendering\n# But you get the idea...probably better to look in Chrome anyway ;)\n# text = bs(resp.text)","key":"CZqnKl0Fl2"},{"type":"output","id":"7kuQTjU4CfhA0vRJdEJlr","data":[],"key":"pAxXejdsnc"}],"key":"iOtWfiyTyU"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"If we search through the result, you may notice that search results are organized into a list (denoted by ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TUkIdzX2BW"},{"type":"inlineCode","value":"li","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GUXMchtGUN"},{"type":"text","value":" for each item). Inside each item is information about the article’s title (in a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UfhUIgC8KQ"},{"type":"inlineCode","value":"div","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n3rg4uPGo3"},{"type":"text","value":" of class ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m6QOeyFS1b"},{"type":"inlineCode","value":"highwire-cite-title","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vbgTuXh0DU"},{"type":"text","value":") and author information (in a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SMIN6geMVv"},{"type":"inlineCode","value":"div","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eBqgx3eiST"},{"type":"text","value":" of calss ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PU1Ti7cK9t"},{"type":"inlineCode","value":"highwire-cite-authors","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"coQuOQeV5F"},{"type":"text","value":").","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZEyzHvtgDM"}],"key":"gEBL08XVfS"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Let’s use this information to ask three questions:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wgCLVggeaO"}],"key":"M6lvdVPmVP"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"How has the rate of publications for a term changed over the years","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"xgEXXDfDLS"}],"key":"KpvYdXyF9R"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Who’s been publishing under that term.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Y4m2FyBFRn"}],"key":"G8uMGfoNiy"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"What kinds of things are people publishing?","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"f15gSDY2Ts"}],"key":"BkPOHU5itB"}],"key":"Iey3YSj2fn"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"For each, we’ll simply use the phrase “neuroscience”, although you could use whatever you like.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"sswMcAjnKb"}],"key":"VZJvZD9g9I"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"To set up this query, we’ll need to use another part of the biorxiv API, the ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"t7SYAP4a83"},{"type":"inlineCode","value":"limit_from","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"NaLHoJ3uf7"},{"type":"text","value":" paramter. This lets us constrain the search to a specific month of the year. That way we can see the monthly submissions going back several years.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"QfOJwpZoRt"}],"key":"MXiLDfeQmG"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"We’ll loop through years / months, and pull out the author and title information. We’ll do this with two dataframes, one for authors, one for articles.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"DDPBw9AQ2p"}],"key":"aXxjlsNXe7"}],"key":"cG0YUwptt7"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define the URL and start/stop years\nstt_year = 2012\nstp_year = 2016\nsearch_term = \"neuroscience\"\nurl_base = \"http://biorxiv.org/search/{}\".format(search_term)\nurl_params = \"%20limit_from%3A{0}-{1}-01%20limit_to%3A{0}-{2}-01%20numresults%3A100%20format_result%3Astandard\"\nurl = url_base + url_params","key":"BAbt84N02A"},{"type":"output","id":"BnvpTH7heXpEHc2PV7O5R","data":[],"key":"IWxyDTgh2M"}],"key":"rhJAo5wOOu"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Now we'll do the scraping...\nall_articles = []\nall_authors = []\nfor yr in tqdm(range(stt_year, stp_year + 1)):\n    for mn in range(1, 12):\n        # Populate the fields with our current query and post it\n        this_url = url.format(yr, mn, mn + 1) \n        resp = requests.post(this_url)\n        html = bs(resp.text)\n        \n        # Collect the articles in the result in a list\n        articles = html.find_all('li', attrs={'class': 'search-result'})\n        for article in articles:\n            # Pull the title, if it's empty then skip it\n            title = article.find('span', attrs={'class': 'highwire-cite-title'})\n            if title is None:\n                continue\n            title = title.text.strip()\n            \n            # Collect year / month / title information\n            all_articles.append([yr, mn, title])\n            \n            # Now collect author information\n            authors = article.find_all('span', attrs={'class': 'highwire-citation-author'})\n            for author in authors:\n                all_authors.append((author.text, title))","key":"Ev2q08WOSw"},{"type":"output","id":"YCSFdBEufcRmTW0NwXvs2","data":[],"key":"tvKAufmd03"}],"key":"EejztVqCku"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# We'll collect these into DataFrames for subsequent use\nauthors = pd.DataFrame(all_authors, columns=['name', 'title'])\narticles = pd.DataFrame(all_articles, columns=['year', 'month', 'title'])","key":"FKhFLcbU6Y"},{"type":"output","id":"lo_ZFaduKQpmMLhJh1iKk","data":[],"key":"HXCR9qRCF4"}],"key":"FqwznUeNOL"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make things easier to cross-reference, we’ll add an ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UGw4t82y4P"},{"type":"inlineCode","value":"id","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Zp2Y935uzH"},{"type":"text","value":" column that’s unique for each title. This way we can more simply join the dataframes to do cool things:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iCByHA6BBs"}],"key":"h4BWjJuM2Z"}],"key":"NfOCCAgcwN"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define a dictionary of title: ID mappings\nunique_ids = {title: ii for ii, title in enumerate(articles['title'].unique())}\narticles['id'] = [unique_ids[title] for title in articles['title']]\nauthors['id'] = [unique_ids[title] for title in authors['title']]","key":"Z5UKQtK0UH"},{"type":"output","id":"YhqoWzAZZ2bjMkVIR0_8i","data":[],"key":"kUxIWtREwx"}],"key":"nPdsWiWK0M"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, we can easily join these two dataframes together if we so wish:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fOc7KUT0me"}],"key":"n7PLulcc10"}],"key":"BLcJoYI7Uw"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"pd.merge(articles, authors, on=['id', 'title']).head()","key":"PoIQdSla1g"},{"type":"output","id":"PgO6ZihhT0MNmDH3QtJe5","data":[{"output_type":"execute_result","execution_count":11,"metadata":{},"data":{"text/html":{"content":"<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>title</th>\n      <th>id</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013</td>\n      <td>11</td>\n      <td>Simultaneous optogenetic manipulation and calc...</td>\n      <td>0</td>\n      <td>Frederick B. Shipley</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2013</td>\n      <td>11</td>\n      <td>Simultaneous optogenetic manipulation and calc...</td>\n      <td>0</td>\n      <td>Christopher M. Clark</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2013</td>\n      <td>11</td>\n      <td>Simultaneous optogenetic manipulation and calc...</td>\n      <td>0</td>\n      <td>Mark J. Alkema</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013</td>\n      <td>11</td>\n      <td>Simultaneous optogenetic manipulation and calc...</td>\n      <td>0</td>\n      <td>Andrew M. Leifer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>11</td>\n      <td>Functional connectivity networks with and with...</td>\n      <td>1</td>\n      <td>Satoru Hayasaka</td>\n    </tr>\n  </tbody>\n</table>\n</div>","content_type":"text/html"},"text/plain":{"content":"   year  month                                              title  id  \\\n0  2013     11  Simultaneous optogenetic manipulation and calc...   0   \n1  2013     11  Simultaneous optogenetic manipulation and calc...   0   \n2  2013     11  Simultaneous optogenetic manipulation and calc...   0   \n3  2013     11  Simultaneous optogenetic manipulation and calc...   0   \n4  2013     11  Functional connectivity networks with and with...   1   \n\n                   name  \n0  Frederick B. Shipley  \n1  Christopher M. Clark  \n2        Mark J. Alkema  \n3      Andrew M. Leifer  \n4       Satoru Hayasaka  ","content_type":"text/plain"}}}],"key":"YSk5rQg322"}],"key":"ehmOi0iViY"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Question 1: How has the published articles rate changed?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MC8yonius3"}],"identifier":"question-1-how-has-the-published-articles-rate-changed","label":"Question 1: How has the published articles rate changed?","html_id":"question-1-how-has-the-published-articles-rate-changed","implicit":true,"key":"mEK9dxwnZw"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This one is pretty easy to ask. Since we have both year / month data about each article, we can plot the number or articles for each group of time. To do this, let’s first turn these numbers into an actual “datetime” object. This let’s us do some clever plotting magic with pandas","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"XAc2gDNj5a"}],"key":"PY3n79kq3B"}],"key":"EFoukC7Tjd"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Add a \"date\" column\ndates = [pd.datetime(yr, mn, day=1)\n         for yr, mn in articles[['year', 'month']].values]\narticles['date'] = dates\n\n# Now drop the year / month columns because they're redundant\narticles = articles.drop(['year', 'month'], axis=1)","key":"IqjaO4ISPI"},{"type":"output","id":"tLwoHeESu5xFYyvpMCljd","data":[],"key":"xX3FnSXgSb"}],"key":"cV83L9bamp"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, we can simply group by month, sum the number of results, and plot this over time:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C7nOsCetfK"}],"key":"JejaezR0Nt"}],"key":"RLorZk1ns0"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"monthly = articles.groupby('date').count()['title'].to_frame()\nax = monthly['title'].plot()\nax.set_title('Articles published per month for term\\n{}'.format(search_term))","key":"UHpPSscwKC"},{"type":"output","id":"jHIJOltDTo0eQc9nCNDvr","data":[{"output_type":"execute_result","execution_count":13,"metadata":{},"data":{}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"465193bdabb8346817faa6b0075df622","path":"/build/465193bdabb8346817faa6b0075df622.png"}}}],"key":"zj1mgeCLhU"}],"key":"VoVdFn1XNh"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can also plot the cumulative number of papers published:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PuE8lktubW"}],"key":"aQDDEdeFie"}],"key":"odEqxV2lFc"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"cumulative = np.cumsum(monthly.values)\nmonthly['cumulative'] = cumulative\n\n# Now plot cumulative totals\nax = monthly['cumulative'].plot()\nax.set_title('Cumulative number of papers matching term \\n{}'.format(search_term))\nax.set_ylabel('Number of Papers')","key":"L7nIcshH5n"},{"type":"output","id":"32-RuHQMih_d_Q_dpu2v8","data":[{"output_type":"execute_result","execution_count":14,"metadata":{},"data":{}},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e1f82db4a6c299d8f7c773c1b0a7ff1f","path":"/build/e1f82db4a6c299d8f7c773c1b0a7ff1f.png"}}}],"key":"xg7wWTetqX"}],"key":"SNPPZyPMy3"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Question 2: Which author uses pre-prints the most?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Vnbr9xHMbJ"}],"identifier":"question-2-which-author-uses-pre-prints-the-most","label":"Question 2: Which author uses pre-prints the most?","html_id":"question-2-which-author-uses-pre-prints-the-most","implicit":true,"key":"OWGZeMz0yy"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"For this one, we can use the “authors” dataframe. We’ll group by author name, and count the number of publications per author:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"gQ4Ez09O3I"}],"key":"Zit1BDbieg"}],"key":"DxQssSMdLX"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Group by author and count the number of items\nauthor_counts = authors.groupby('name').count()['title'].to_frame('count')\n\n# We'll take the top 30 authors\nauthor_counts = author_counts.sort_values('count', ascending=False)\nauthor_counts = author_counts.iloc[:30].reset_index()","key":"rM8qB8OnJV"},{"type":"output","id":"InaC3tnq9l3JOy7-i_46p","data":[],"key":"hSfNghh935"}],"key":"qYmDBtMCw1"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We’ll use some ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QPpYWHjJFb"},{"type":"inlineCode","value":"pandas","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DkZJ4YhLCH"},{"type":"text","value":" magical gugu to get this one done. Who is the greatest pre-print neuroscientist of them all?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E54E0DNDWe"}],"key":"IZDZXP7mMU"}],"key":"zLPAGGivi8"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# So we can plot w/ pretty colors\ncmap = plt.cm.viridis\ncolors = cmap(author_counts['count'].values / float(author_counts['count'].max()))\n\n# Make the plot\nfig, ax = plt.subplots(figsize=(10, 5))\nax = author_counts.plot.bar('name', 'count', color=colors, ax=ax)\n_ = plt.setp(ax.get_xticklabels(), rotation=45, ha='right')","key":"oYhqVlDUGj"},{"type":"output","id":"HSvJK-cSHtHmD7yvw7uJ8","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"4fa4b3ac805d8eb479253394bf558b4c","path":"/build/4fa4b3ac805d8eb479253394bf558b4c.png"}}}],"key":"nrFmX5BwWJ"}],"key":"JQBfOhc50l"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Rather than saying congratulations to #1 etc here, I’ll just take this space to say that all of these researchers are awesome for helping push scientific publishing technologies into the 21st century ;)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ATLlbPnHK3"}],"key":"VfFnV74mm3"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Question 3: What topics are covered in the titles?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"QwBT93jqrg"}],"identifier":"question-3-what-topics-are-covered-in-the-titles","label":"Question 3: What topics are covered in the titles?","html_id":"question-3-what-topics-are-covered-in-the-titles","implicit":true,"key":"Q5qRuHrvXz"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"For this one we’ll use a super floofy answer, but maybe it’ll give us something pretty. We’ll use the wordcloud module, which implements ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"x6rRqbqRhT"},{"type":"inlineCode","value":"fit","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"oZlIMMgcEW"},{"type":"text","value":" and ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Ou1FXDIWGK"},{"type":"inlineCode","value":"predict","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"D1YXDmR4jw"},{"type":"text","value":" methods similar to scikit-learn. We can train it on the words in the titles, and then create a pretty word cloud using these words.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"ObtGJp2EgC"}],"key":"ElQ3AXpcIK"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"To do this, we’ll use the ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"CCaiPqBtwh"},{"type":"inlineCode","value":"wordcloud","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"G6Rrs2fOAz"},{"type":"text","value":" module along with ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"bcZPyi8Erg"},{"type":"inlineCode","value":"sklearn","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Hk6aEUPmj1"},{"type":"text","value":"’s stop words (which are also useful for text analysis, incidentally)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"wVnWphWsjG"}],"key":"iMKVBlqxcA"}],"key":"ScWb4UFpUF"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"import wordcloud as wc \nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS","key":"wlKyqWIlgk"},{"type":"output","id":"aYXsF996ztaZiif8x1mXG","data":[],"key":"oVTsZMikY0"}],"key":"fbrCdaOvzg"},{"type":"block","kind":"notebook-code","data":{"collapsed":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# We'll collect the titles and turn them into one giant string\ntitles = articles['title'].values\ntitles = ' '.join(titles)\n\n# Then define stop words to use...we'll include some \"typical\" brain words\nour_stop_words = list(ENGLISH_STOP_WORDS) + ['brain', 'neural']","key":"Z7B2jY5TWK"},{"type":"output","id":"mhl507kiRe7Nf7EJGAZnU","data":[],"key":"NAY68UMnIg"}],"key":"Q05LRXfTIk"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, generating a word cloud is as easy as a call to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LTAMdCkJNa"},{"type":"inlineCode","value":"generate_from_text","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZuIH27131K"},{"type":"text","value":". Then we can output in whatever format we like","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Vi6My3g0u0"}],"key":"VzHCBGN2Y4"}],"key":"rp65XsEfQ8"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# This function takes a buch of dummy arguments and returns random colors\ndef color_func(word=None, font_size=None, position=None,\n               orientation=None, font_path=None, random_state=None):\n    rand = np.clip(np.random.rand(), .2, None)\n    cols = np.array(plt.cm.rainbow(rand)[:3])\n    cols = cols * 255\n    return 'rgb({:.0f}, {:.0f}, {:.0f})'.format(*cols)","key":"zy3dK2ojSZ"},{"type":"output","id":"0QmSxI8Rc9Zg9EBL4-Gvy","data":[],"key":"vDl4ZKKhWN"}],"key":"La9ng6uXJo"},{"type":"block","kind":"notebook-code","data":{"collapsed":false},"children":[{"type":"code","lang":"python","executable":true,"value":"# Fit the cloud\ncloud = wc.WordCloud(stopwords=our_stop_words,\n                     color_func=color_func)\ncloud.generate_from_text(titles)\n\n# Now make a pretty picture\nim = cloud.to_array()\nfig, ax = plt.subplots()\nax.imshow(im, cmap=plt.cm.viridis)\nax.set_axis_off()","key":"khr6iVzLpY"},{"type":"output","id":"d5AP-BZMr9y7jl-y2fR-I","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0212a32208ad4b1d80c2e2f5273c1baf","path":"/build/0212a32208ad4b1d80c2e2f5273c1baf.png"}}}],"key":"KoKE6qlv4S"}],"key":"EdZYNjwWAN"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Looks like those cognitive neuroscience folks are leading the charge towards pre-print servers. Hopefully in the coming years we’ll see increased adoption from the systems and cellular fields as well.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZI4daXTbEl"}],"key":"un9u85vt6X"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Wrapup","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"S6n3PCQqay"}],"identifier":"wrapup","label":"Wrapup","html_id":"wrapup","implicit":true,"key":"FK5oB4AUnB"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Here we played with just a few questions that you can ask with some simple web scraping and the useful tools in python. There’s a lot more that you could do with it, but I’ll leave that up to readers to figure out for themselves :)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"xowX4BIE2c"}],"key":"wMv58RJZER"}],"key":"QmJxem7TmU"}],"key":"Z590exk19E"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Visualizing publication bias","url":"/blog/2016/2016-11-30-funnel-plots","group":"2016"},"next":{"title":"Brainy Jingle Bells","url":"/blog/2016/2016-12-23-christmas-ecog-plot","group":"2016"}}},"domain":"http://localhost:3000"}