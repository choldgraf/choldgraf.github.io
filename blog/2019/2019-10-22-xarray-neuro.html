<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Analyzing intracranial electrophysiology data with xarray - Welcome</title><meta property="og:title" content="Analyzing intracranial electrophysiology data with xarray - Welcome"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png"/><meta property="og:image" content="/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@choldgraf"/><meta name="twitter:title" content="Analyzing intracranial electrophysiology data with xarray - Welcome"/><meta name="twitter:image" content="/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png"/><meta name="twitter:alt" content="Analyzing intracranial electrophysiology data with xarray - Welcome"/><link rel="stylesheet" href="/build/_assets/app-SP33RAUV.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-G5PMZM6RPE"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-G5PMZM6RPE');</script><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Chris Holdgraf</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"><div class="relative inline-block mx-2 grow-0"><a class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75" href="/about">About</a></div><div class="relative inline-block mx-2 grow-0"><a class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75" href="/projects">Projects</a></div><div class="relative inline-block mx-2 grow-0"><a class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75" href="/publications">Publications</a></div><div class="relative inline-block mx-2 grow-0"><a class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75" href="/talks">Talks</a></div><div class="relative inline-block mx-2 grow-0"><a aria-current="page" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75 border-b border-stone-200" href="/blog">Blog</a></div></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"><div class="relative" data-headlessui-state=""><div><button class="flex text-sm bg-transparent rounded-full focus:outline-none" id="headlessui-menu-button-:Rr4op:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open Menu</span><div class="flex items-center text-stone-200 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="p-1"><path fill-rule="evenodd" d="M10.5 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z" clip-rule="evenodd"></path></svg></div></button></div></div></div><div class="hidden sm:block"><a href="https://chrisholdgraf.com/rss.xml" target="_blank" rel="noopener noreferrer" class="inline-block px-4 py-2 mx-1 mt-0 leading-none border rounded text-md border-stone-700 dark:border-white text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 hover:bg-neutral-100">RSS</a></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"><a class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded" href="/about">About</a><a class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded" href="/projects">Projects</a><a class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded" href="/publications">Publications</a><a class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded" href="/talks">Talks</a><a aria-current="page" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded active" href="/blog">Blog</a></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Welcome" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Welcome</a><a title="About me" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/about">About me</a><a title="Projects" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/projects">Projects</a><a title="Publications" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/publications">Publications</a><a title="Talks" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/talks">Talks</a><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Blog" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/blog">Blog</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R1mp8p:" class="pl-3 pr-[2px] collapsible-content"><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2025" class="block break-words rounded py-2 grow cursor-pointer">2025</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rrmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rrmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2024" class="block break-words rounded py-2 grow cursor-pointer">2024</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1bmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1bmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2023" class="block break-words rounded py-2 grow cursor-pointer">2023</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2022" class="block break-words rounded py-2 grow cursor-pointer">2022</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2bmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2bmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2021" class="block break-words rounded py-2 grow cursor-pointer">2021</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R2rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R2rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2020" class="block break-words rounded py-2 grow cursor-pointer">2020</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3bmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R3bmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2019" class="block break-words rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 cursor-pointer">2019</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R3rmp8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:R3rmp8p:" class="pl-3 pr-[2px] collapsible-content"><a title="Three things I love about CircleCI" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-01-29-three-things-circleci">Three things I love about CircleCI</a><a title="Thoughts from the Jupyter team meeting 2019" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-03-16-jupyter-dev">Thoughts from the Jupyter team meeting 2019</a><a title="A few recent talks" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-06-25-a-few-talks">A few recent talks</a><a title="Automating Jupyter Book deployments with CI/CD" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-10-11-automating-jb">Automating Jupyter Book deployments with CI/CD</a><a title="What would Rust-style governance look like in Jupyter?" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-10-13-rust-jupyter-governance">What would Rust-style governance look like in Jupyter?</a><a title="Analyzing intracranial electrophysiology data with xarray" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/blog/2019/2019-10-22-xarray-neuro">Analyzing intracranial electrophysiology data with xarray</a><a title="What would Python-style governance look like in Jupyter?" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-10-27-jupyter-governance-python">What would Python-style governance look like in Jupyter?</a><a title="Testing Pandoc and Jupyter Notebooks" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/blog/2019/2019-11-11-ipynb-pandoc">Testing Pandoc and Jupyter Notebooks</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2018" class="block break-words rounded py-2 grow cursor-pointer">2018</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4bmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4bmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2017" class="block break-words rounded py-2 grow cursor-pointer">2017</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R4rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R4rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2016" class="block break-words rounded py-2 grow cursor-pointer">2016</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R5bmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R5bmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="2015" class="block break-words rounded py-2 grow cursor-pointer">2015</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R5rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R5rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/choldgraf/choldgraf.github.io" title="GitHub Repository: choldgraf/choldgraf.github.io" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><a href="https://github.com/choldgraf/choldgraf.github.io/blob/main/blog/2019/2019-10-22-xarray-neuro.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Analyzing intracranial electrophysiology data with xarray</h1><header class="mt-4 not-prose"><div class="grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R2t8top:" data-state="closed">Chris Holdgraf</button><a class="ml-1" href="https://orcid.org/0000-0002-2391-0678" target="_blank" rel="noopener noreferrer" title="ORCID (Open Researcher and Contributor ID)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="inline-block text-gray-400 hover:text-[#A9C751] -translate-y-[0.1em]"><path d="M21.8 12c0 5.4-4.4 9.8-9.8 9.8S2.2 17.4 2.2 12 6.6 2.2 12 2.2s9.8 4.4 9.8 9.8zM8.2 5.8c-.4 0-.8.3-.8.8s.3.8.8.8.8-.4.8-.8-.3-.8-.8-.8zm2.3 9.6h1.2v-6h1.8c2.3 0 3.3 1.4 3.3 3s-1.5 3-3.3 3h-3v1.1H9V8.3H7.7v8.2h5.9c3.3 0 4.5-2.2 4.5-4.1s-1.2-4.1-4.3-4.1h-3.2l-.1 7.1z"></path></svg></a><a class="ml-1" href="https://twitter.com/choldgraf" target="_blank" rel="noopener noreferrer" title="Twitter: choldgraf"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="inline-block text-gray-400 hover:text-[#1DA1F2] -translate-y-[0.1em]"><path d="M22.7 5.4c-.8.3-1.7.6-2.5.7.9-.5 1.6-1.4 1.9-2.4-.9.5-1.8.9-2.8 1.1-1.7-1.8-4.4-1.9-6.2-.2-1.1 1.1-1.6 2.7-1.3 4.2-3.5-.3-6.8-1.9-9-4.7-.4.7-.6 1.5-.6 2.2 0 1.5.7 2.8 1.9 3.6-.7 0-1.4-.2-2-.5v.1c0 2.1 1.5 3.9 3.5 4.3-.6.2-1.3.2-2 .1.6 1.8 2.2 3 4.1 3-1.6 1.2-3.5 1.9-5.4 1.9-.3 0-.7 0-1-.1 2 1.3 4.3 2 6.7 2 8.1 0 12.5-6.7 12.5-12.5v-.6c.8-.6 1.6-1.3 2.2-2.2"></path></svg></a></span></div><div class="text-sm"><div>2i2c<!-- --> </div><div>Project Jupyter<!-- --> </div></div></div></header><div class="flex mt-2 text-sm font-light"><time dateTime="2019-10-22" class="">October 22, 2019</time></div></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>Over the last few years, it has been exciting to see the xarray project evolve,
add new functionality, and mature. This post is an attempt at
giving xarray another visit to see how it could integrate into electrophysiology
workflows.</p><h3 id="a-quick-background-on-our-data" class="relative group"><span class="heading-text">A quick background on our data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#a-quick-background-on-our-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>It is common in neuroscience to ask individuals to perform a task over and over again. You record
the activity in the brain each time they perform the task (called an “epoch” or a “trial”).
Time is recorded relative to some <em>onset</em> when the task begins. That is <code>t==0</code>. The result
is usually a matrix of <code>epochs x channejupyls x time</code>. You can do a lot of stuff with this
data, but our task in this paper is to detect changes in neural activity at trial onset (<code>t==0</code>).</p><p>In our case, we’ve got a small dataset from <cite class="" data-state="closed"><a href="https://doi.org/10.3389/fnsys.2017.00061" target="_blank" rel="noreferrer" class="hover-link">an old paper of mine</a></cite>.
The repository contains
several tutorial notebooks and sample data to describe predictive modeling
in cognitive neuroscience. <a target="_blank" rel="noreferrer" href="https://github.com/choldgraf/paper-encoding_decoding_electrophysiology" class="">You can find the repository here</a>. The task that individuals were performing was passively
listening to spoken sentences through a speaker. While they did this, we recorded electrical
activity at the surface of their brain (these were surgical patients, and had implanted electrodes
under their scalp).</p><p>In the <a href="https://github.com/choldgraf/paper-encoding_decoding_electrophysiology/blob/master/notebooks/FeatureExtraction.ipynb" class="italic" target="_blank" rel="noreferrer" data-state="closed">Feature Extraction</a> notebook,
I covered how to do some simple data manipulation and feature extraction with
timeseries analysis. Let’s try to re-create some of the main steps in that tutorial,
but now using xarray as an in-memory structure for our data.</p><div id="VpZliJjwcW" class="relative group/block"><p><strong>Note</strong>: The goal here is to learn a bit about xarray moreso than to discuss
ecog modeling, so I’ll spend more time talking about my thoughts on the various
functions/methods/etc in Xarray than talking about neuroscience.</p></div><div id="lB9myF0Oh9" class="relative group/block"><p>In this post, we’ll perform a few common processing and extraction steps.
The goal is to do a few munging operations that require manipulating data
and visualizing simple statistics.</p></div><div id="Pesr85X6yc" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Imports we&#x27;ll use later
import mne
import numpy as np
import matplotlib.pyplot as plt
from download import download
import os
from sklearn.preprocessing import scale
import xarray as xr
xr.set_options(display_style=&quot;html&quot;)

import warnings
warnings.simplefilter(&#x27;ignore&#x27;)
%matplotlib inline</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="KkL8_nTupj_PlvPPsU2_I" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="N9suYfbbUM" class="relative group/block"><p>We’ll load the data from my GitHub repository (probably not the most efficient
way to store or retrieve the data, but hey, this was 3 years ago :-) ).</p></div><div id="eMdVrFhUvq" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">url_epochs = &quot;https://github.com/choldgraf/paper-encoding_decoding_electrophysiology/blob/master/raw_data/ecog-epo.fif?raw=true&quot;

path_data = download(url_epochs, &#x27;./ecog-epo.fif&#x27;, replace=True)
ecog = mne.read_epochs(path_data, preload=True)
os.remove(path_data)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2GYrk5SXLCATNe21dHcnU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>file_sizes:   0%|                                   | 0.00/8.36M [00:00&lt;?, ?B/s]</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Downloading data from https://raw.githubusercontent.com/choldgraf/paper-encoding_decoding_electrophysiology/master/raw_data/ecog-epo.fif?raw=true (8.0 MB)

</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>file_sizes: 100%|██████████████████████████| 8.36M/8.36M [00:00&lt;00:00, 12.5MB/s]</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Successfully downloaded file to ./ecog-epo.fif
Reading ./ecog-epo.fif ...
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Isotrak not found
    Found the data of interest:
        t =   -1500.00 ...    5996.67 ms
        0 CTF compensation matrices available
29 matching events found
No baseline correction applied
Not setting metadata
0 projection items activated
</span></code></pre></div></div></div><div id="dsPDb20t1i" class="relative group/block"><p>Here’s what the raw data looks like - each horizontal line is electrical activity
in a channel over time. The faint vertical green lines show the onset of
each trial (they are concatenated together, but in reality there’s a bit of time
between trials). This will be one of the last times we use MNE hopefully.</p></div><div id="ng3jM1IGu0" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">_ = ecog.plot(scalings=&#x27;auto&#x27;, n_epochs=5, n_channels=10)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UblpdiuEFMtUZ4zjUlULL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/fc24837c97da2d130f181274745e4ae0.png" alt="&lt;Figure size 480x320 with 5 Axes&gt;"/></div></div><div id="iRAwQjTlh4" class="relative group/block"><h2 id="converting-to-xarray" class="relative group"><span class="heading-text">Converting to xarray</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#converting-to-xarray" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>First off, we’ll define a helper function that
converts the MNE Epochs object into an xarray DataArray object.
DataArrays provide an N-Dimensional representation of data, but with
the option to include a lot of extra metadata.</p><p>DataArrays are useful because you can include information
<em>about each dimension</em> of the data. For example, we can tell our
DataArray the name, values, and units of each dimension. In this case,
in our case one dimension is “time” so we can label it as such.</p></div><div id="wzUZ2KUQ1v" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def epochs_to_dataarray(epochs):
    &quot;&quot;&quot;A simple function to convert an Epochs object to DataArray&quot;&quot;&quot;
    da = xr.DataArray(
    epochs._data,
    dims=[&#x27;epoch&#x27;, &#x27;channel&#x27;, &#x27;time&#x27;],
    coords={
        &#x27;time&#x27;: ecog.times,
        &#x27;channel&#x27;: ecog.ch_names,
        &#x27;epoch&#x27;: range(ecog._data.shape[0])
    },
    name=&#x27;Sample dataset&#x27;,
    attrs=dict(ecog.info)
    )
    return da</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="M1u-BnHapPiQMGEoUj4I_" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Yj0P25U9Ne" class="relative group/block"><p>Just look at all the metadata that we were able to pack into the DataArray.
Almost all of MNE’s metadata fit nicely into <code>.attrs</code>.</p></div><div id="bPL5yqbKHX" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># There&#x27;s quite a lot of output, so keep scrolling down!
da = epochs_to_dataarray(ecog)
da</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="6KKQ9CQ19l72uTsS2fMuB" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="xnmWYwCqsj" class="relative group/block"><p>The data consists of many trials, channels, and timepoints.
Let’s start by selecting a time region within each trial that
we can visualize more cleanly.</p><h2 id="subsetting-out-data-with-da-sel" class="relative group"><span class="heading-text">Subsetting out data with <code>da.sel</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#subsetting-out-data-with-da-sel" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In xarray, we select items with the <code>sel</code> and <code>isel</code> method. This
behaves kind of like the pandas <code>loc</code> and <code>iloc</code> methods, however
because we have named dimensions, we can directly specify them in
our call.</p></div><div id="o7N6YzpqyU" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># We&#x27;ll drop a subset of timepoints for visualization
da = da.sel(time=slice(-1, 3))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ho8d2w7UkiMHJsJiepM_3" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="QBsr1ldzgG" class="relative group/block"><p>Now let’s calculate the average across all epochs for each electrode/time point.
This is a <strong>reduction</strong> of our data array, in that it reduces the number of dimensions.
Xarray has many of the same statistical methods that NumPy does. An interesting
twist is that you can specify named dimensions instead of simply an <code>axis=&lt;integer&gt;</code>
argument. In addition, we’ll choose the colors that we’ll use for cycling through
our channels - because we can quickly reference the channels axis by name, we don’t
need to remember which axis corresponds to channels.</p></div><div id="u59J73LKsO" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
n_channels = da[&#x27;channel&#x27;].shape[0]
ax.set_prop_cycle(color=plt.cm.viridis(np.linspace(0, 1, n_channels)))
da.mean(dim=&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;, hue=&#x27;channel&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="CkTH63gSXfqNZIBafgsRM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/d2a005471e8a3037ad4047456d195f42.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="LRjaB8pARH" class="relative group/block"><p>It doesn’t look like much is going on...let’s see if we can clean it up a bit.</p></div><div id="g1I18zKEK6" class="relative group/block"><h2 id="de-meaning-the-data-with-da-where" class="relative group"><span class="heading-text">De-meaning the data with <code>da.where</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#de-meaning-the-data-with-da-where" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>First off - we’ll subtract the “pre-baseline mean” from each trial.
This makes it easier to visualize how each channel’s activity <em>changed</em>
at time == 0.</p><p>To accomplish this we’ll use <code>da.where</code>. This takes some kind of
boolean-style mask, does a bunch of clever projections according to the
names of coordinates, and returns the dataarray masked values removed
(as <code>NaN</code>s) and other values unchanged. We can use this to calculate the
mean of each channel / epoch <em>only for the pre-baseline timepoints</em>.</p></div><div id="kD4BrDvqFP" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># This returns a version of the data array with NaNs where the query is False
# The dimensions will intelligently broadcast 
prebaseline_mean = da.where(da.time &lt; 0).mean(dim=&#x27;time&#x27;)
da_demeaned = da - prebaseline_mean</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ncCxTs9K0TQNE8fL-vZ6H" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AzHm4CY4AK" class="relative group/block"><p>Now we can visualize the de-baseline-meaned data</p></div><div id="m1FBQcrmIj" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
ax.set_prop_cycle(color=plt.cm.viridis(np.linspace(0, 1, da[&#x27;channel&#x27;].shape[0])))
da_demeaned.mean(dim=&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;, hue=&#x27;channel&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="8xkSs_0RtWoTEJydShQxh" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/353af84f275a78ecad4d82e77d4e808b.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="XsBZn3f9eF" class="relative group/block"><p>Hmmm, there still doesn’t seem to be much going on (that channel down
at the bottom looks noisy to me, rather than having a meaningful signal)
so let’s transform this signal into something with a bit more SNR to it.</p></div><div id="sQLCx2dJSa" class="relative group/block"><h2 id="extracting-a-more-useful-feature-with-xr-apply-ufunc" class="relative group"><span class="heading-text">Extracting a more useful feature with <code>xr.apply_ufunc</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#extracting-a-more-useful-feature-with-xr-apply-ufunc" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Without going into too much details on the neuroscience, iEEG data is
particularly useful because there is information about neuronal activity in
the higher frequency parts of the signal (AKA, parts of the electrical signal that
change very quickly, but have very low amplitude). To pull that out, we’ll do the following:</p><ul><li>High-pass filter the signal, which will remove all the slow-moving components</li><li>Calculate the <em>envelope</em> of the signal, which will tell us the power of
high-frequency activity over time.</li></ul><h3 id="high-pass-filtering-the-signal" class="relative group"><span class="heading-text">High-pass filtering the signal</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#high-pass-filtering-the-signal" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>MNE has a lot of nice functions for filtering a timeseries. Most of these
operate on numpy arrays instead of MNE objects. We’ll use
xarray’s <code>apply_ufunc</code> function to simply map that function onto our dataarray.
xarray should keep track of the metadata (e.g. coordinates etc) and output a
new DataArray with updated values.</p></div><div id="PKCRREBo1y" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">flow = 80
fhigh = 140
da_lowpass = xr.apply_ufunc(
    mne.filter.filter_data, da,
   kwargs=dict(
       sfreq=da.sfreq,
       l_freq=flow,
       h_freq=fhigh,
   )
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="wVUpFQaKgvRHd1BaNVcU2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Setting up band-pass filter from 80 - 1.4e+02 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 80.00
- Lower transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 70.00 Hz)
- Upper passband edge: 140.00 Hz
- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 145.00 Hz)
- Filter length: 99 samples (0.330 sec)

</span></code></pre></div></div></div><div id="aG0i2WFZN3" class="relative group/block"><p>Visualizing our data, we can see all the slower fluctuations (e.g. long arcs over time)
are gone.</p></div><div id="BgtUx1bqDi" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
da_lowpass.mean(dim=&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="oQv6AHqUAyABiyzYj95vv" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/8d4f3353e4f30638468ea9b2683d3bb4.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="UHvG4ns6uF" class="relative group/block"><h3 id="calculate-the-envelope-of-this-signal-with-da-groupby" class="relative group"><span class="heading-text">Calculate the envelope of this signal with <code>da.groupby</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#calculate-the-envelope-of-this-signal-with-da-groupby" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Next, we’ll calculate the <strong>envelope</strong> of the high-pass-filtered data. This is roughly
the <strong>power</strong> that is present in these high frequencies over time. We do so by using
something called a <strong>hilbert transform</strong>.</p><p>MNE also has a function for applying Hilbert transforms to data, but it has a weird quirk
that expects the data to be of a particular shape. We can work around this by using our
DataArray’s <code>groupby</code> method. This works similar to <code>DataFrame.groupby</code> - we’ll iterate
through each channel, which will return a DataArray with shape <code>epochs x timepoints</code>.
We can then calculate the Hilbert transform in each and re-combine into the original shape.</p></div><div id="OgpemIwjd6" class="relative group/block"><p><strong>Note</strong>: This can be an expensive operation depending on the number of channels/epochs and
the length of each trial. This might be a good place to insert paralellization via Dask.</p></div><div id="rxfKiRUAl9" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def hilbert_2d(array):
    &quot;&quot;&quot;Perform a Hilbert transforms on an (n_channels, n_times) array.&quot;&quot;&quot;
    for ii, channel in enumerate(array):
        array[ii] = mne.filter._my_hilbert(channel, envelope=True)
    return array

da_hf_power = da_lowpass.groupby(da.coords[&#x27;epoch&#x27;]).apply(hilbert_2d)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="r-MV7fQBWdYa8OeFrKpxV" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ZSqLDnQQvu" class="relative group/block"><p>The output dataarray should be the exact same shape, because we haven’t done any dimensional reductions.
If we take a look at the resulting data, we can see what seems to be more structure in there:</p></div><div id="aJ1s3kI68K" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
da_hf_power.mean(dim=&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;, hue=&#x27;channel&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xdMQjTYOwtdikVgzTn1GJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/bd0b6ea1aadfee7a494630159662ad6b.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="rF3JTbPuID" class="relative group/block"><h2 id="cleaning-up-our-hfa-data" class="relative group"><span class="heading-text">Cleaning up our HFA data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#cleaning-up-our-hfa-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Next let’s clean up this high-frequency activity (HFA) data.</p></div><div id="g7caOfHdlp" class="relative group/block"><h3 id="z-scoring-our-array" class="relative group"><span class="heading-text">Z-scoring our array</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#z-scoring-our-array" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Instead of simple de-meaning
the data like before, we’ll <strong>re-scale</strong> our data using the same baseline timepoints.
What we’d like to do is the following:</p><ul><li>Calculate the mean and standard deviation across trials of all pre-baseline data values, per channel</li><li>Z-score each channel using this mean and standard deviation</li></ul><p>Once again we’ll use the groupby / apply combination to apply our function to subsets
of the data.</p></div><div id="JfCfju7QOz" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># For each channel, apply a z-score that uses the mean/std of pre-baseline activity for all trials
def z_score(activity):
    &quot;&quot;&quot;Take a DataArray and apply a z-score using the baseline&quot;&quot;&quot;
    baseline = activity.where(activity.time &lt; -.1 )
    return (activity - np.nanmean(baseline)) / np.nanstd(baseline)

da_hf_zscored = da_hf_power.groupby(&#x27;channel&#x27;).apply(z_score)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="nUpuEjatlG455RQ_uwAf3" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="CTuYCZcNUD" class="relative group/block"><p>Taking a look at the result, we can see a much cleaner separation of activity for
some of the channels after <code>time==0</code>.</p></div><div id="SPJdkDMmKg" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
da_hf_zscored.mean(dim=&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;, hue=&#x27;channel&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="IxKFNSfPdV_jnvUIbyxAj" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/6fa8536695567fa2cfa95d3ab343e1a2.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="Gkn7H0BRZs" class="relative group/block"><h3 id="smoothing-our-hfa-data" class="relative group"><span class="heading-text">Smoothing our HFA data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#smoothing-our-hfa-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Finally, let’s smooth this HFA so it has less jitter to it, and pick a smaller window that
removes some of the filtering artifacts at the edges.</p><p>We’ll use the same <code>filter_data</code> function as before, but this time
applied with the <code>.groupby</code> and <code>.apply</code> combination to show two ways
of accomplishing the same thing. We’ll also use <code>.sel</code> to pick a subset
of time for visualization</p></div><div id="vfmP8nFim1" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">da_hf_zscored_lowpass = da_hf_zscored.groupby(&#x27;epoch&#x27;).apply(
    mne.filter.filter_data,
    sfreq=da.sfreq,
    l_freq=None,
    h_freq=10,
    verbose=False
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="K9pa1kp26GFdnjq_eeKah" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="EK6DvfAbfp" class="relative group/block"><p>Note that quickly selecting a subset of timepoints if we used numpy is much more verbose. Here’s
a quick comparison:</p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Numpy alone
mask_time = (times &gt; -.8) * (times &lt; 2.8)
epoch_dim = 0
da_hf_zscored_lowpass[..., mask_time].mean(epoch_dim)

# xarray
da_hf_zscored_lowpass.sel(time=slice(-.8, 2.8)).mean(dim=&#x27;epoch&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></div><div id="Cyt4QglC4o" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
da_hf_zscored_lowpass.mean(dim=&#x27;epoch&#x27;).sel(time=slice(-.8, 2.8)).plot.line(x=&#x27;time&#x27;, hue=&#x27;channel&#x27;)
ax.get_legend().remove()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="3Og4HQrh2-w712QsQxLRf" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/a1097f62a3a45fd41be89555a8d5333c.png" alt="&lt;Figure size 1080x360 with 1 Axes&gt;"/></div></div><div id="FyHJ04TTVn" class="relative group/block"><p>Now we can see there are clearly some channels that become active just after <code>t==0</code>.
We can reduce our dataarray to a single dimension of “mean post-baseline activity in each channel”
and convert it to a DataFrame for further processing:</p></div><div id="GkwYmKUdqJ" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Find the channel with the most activity by first converting to a dataframe
total_activity = da_hf_zscored_lowpass.sel(time=slice(0, 2)).mean(dim=[&#x27;epoch&#x27;, &#x27;time&#x27;])
total_activity = total_activity.to_dataframe()
total_activity.head()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="wucP5SpZgcWRio9xW-_RU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="y5JhE7FQRx" class="relative group/block"><p>Let’s grab the channel with maximal activation to look into a bit further.</p></div><div id="xb6Pk5NXsE" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">max_chan = total_activity.squeeze().sort_values(ascending=False).index[0]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Ebq8YiGUMpvAlUe7g2AvQ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AC2nHBi2z6" class="relative group/block"><h2 id="time-frequency-analysis" class="relative group"><span class="heading-text">Time frequency analysis</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#time-frequency-analysis" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>As a final step, let’s <strong>expand</strong> our DataArray and add another dimension.
In the above steps we specifically focused on high-frequency activity. A more
common approach is to first create a <strong>spectrogram</strong> of your data to see activity
across many frequencies.</p><p>To do this, we’ll use another MNE function for creating a <strong>Time-Frequency Representation</strong>
or TFR. We’ll define a range of frequencies, and apply MNE’s function <em>directly on our DataArray</em>.
This will return a NumPy array with the filtered values.</p></div><div id="a0t6LyMfjw" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">frequencies = [2**ii for ii in np.arange(2, 9, .5)]
tfr = mne.time_frequency.tfr_array_morlet(
    da,
    sfreq=da.sfreq,
    freqs=frequencies,
    n_cycles=4,
)

# Take the absolute value to throw out the non-real parts of the numbers
tfr = np.abs(tfr)
tfr[:2, :2, :2, :2]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="pSL4aXojfJqRAlj7N4cl0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div class="font-mono text-sm whitespace-pre-wrap"><code><span>array([[[[160.04103045, 160.38413909],
         [171.73704543, 175.09249553]],

        [[283.28699104, 285.21855726],
         [241.65630528, 245.77098295]]],


       [[[ 93.99546124,  94.4406537 ],
         [ 78.02050045,  79.15324341]],

        [[ 47.85148993,  49.90845151],
         [ 53.97221461,  54.55793674]]]])</span></code></div></div></div><div id="k11IScku1p" class="relative group/block"><h3 id="convert-this-data-into-a-dataarray-with-expand-dims" class="relative group"><span class="heading-text">Convert this data into a DataArray with <code>.expand_dims</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#convert-this-data-into-a-dataarray-with-expand-dims" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="Bhhsqq3uLh" class="relative group/block"><p>Next, we’ll convert this into a DataArray by using the metadata from our original
DataArray. We can use the <code>expand_dims</code> method to create a new dimension for our DataArray.
We’ll use this to store frequency information.</p><p>We’ll then reshape our new DataArray so that it matches the output of the MNE function,
and use the <code>copy</code> method to create a new DataArray. By supplying the <code>data=</code> argument
to copy, we directly insert the new data inside the generated DataArray.</p></div><div id="H4RI2hClI8" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">da_tfr = (da
    .expand_dims(frequency=frequencies)
    .transpose(&#x27;epoch&#x27;, &#x27;channel&#x27;, &#x27;frequency&#x27;, &#x27;time&#x27;)
    .copy(data=np.log(tfr))
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="vc6VRQHc5bqmmtyyZ3RxU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="WOcBnUC0Hn" class="relative group/block"><p>We can now visualize this time-frequency representation over time</p></div><div id="FCJdgA14rx" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, ax = plt.subplots(figsize=(15, 5))
(da_tfr
    .sel({&#x27;frequency&#x27;: slice(None, 180), &#x27;channel&#x27;: max_chan})
    .mean(&#x27;epoch&#x27;)
    .plot.imshow(x=&#x27;time&#x27;, y=&#x27;frequency&#x27;)
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="oMkkjabnqZSa0mAO993z7" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/3d6257be54ef134bc9b4e2ea4ab2d85d.png" alt="&lt;Figure size 1080x360 with 2 Axes&gt;"/></div></div><div id="M6Ygv1csTb" class="relative group/block"><p>Similar to our one-dimensional visualizations above, it can be hard to visualize
relative changes in activity over a baseline (particularly because the amplitude scales
inversely with the frequency).</p><p>Let’s apply a re-scaling function to our data so that
we can see things more clearly. This time we’ll use MNE’s <code>rescale</code> function, which
acts similarly to our <code>zscore</code> function above.</p></div><div id="abzNerVU79" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">da_tfr_baselined = xr.apply_ufunc(
    mne.baseline.rescale,
    da_tfr,
    kwargs={&#x27;times&#x27;: da_tfr.coords[&#x27;time&#x27;], &#x27;baseline&#x27;: (None, -.1), &quot;mode&quot;: &#x27;zscore&#x27;}
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="aJve-p1hBG1T7FrrRbG_A" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Applying baseline correction (mode: zscore)
</span></code></pre></div></div></div><div id="sPl2kICSCz" class="relative group/block"><p>again, the result should be a DataArray, so we can directly visualize it:</p></div><div id="CSi20IT9DM" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">(da_tfr_baselined
    .sel({&#x27;frequency&#x27;: slice(None, 180), &#x27;channel&#x27;: max_chan, &#x27;time&#x27;: slice(-.8, 2.5)})
    .mean(&#x27;epoch&#x27;)
    .plot.imshow(x=&#x27;time&#x27;, y=&#x27;frequency&#x27;)
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="s7kbXzJNZ-mYjC4N0AMZl" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/0e4ee40776d84c7b267e77baf6850539.png" alt="&lt;Figure size 432x288 with 2 Axes&gt;"/></div></div><div id="efcLqnan0e" class="relative group/block"><p>Now we can see a clear increase in activity in the higher frequencies at <code>t==0</code>.</p></div><div id="HrAe9Q3vAg" class="relative group/block"><h2 id="combining-the-two-with-xr-merge" class="relative group"><span class="heading-text">Combining the two with <code>xr.merge</code></span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#combining-the-two-with-xr-merge" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Finally, let’s combine these two DataArrays into one. We know that they
share much of the same metadata - the first is “Amplitude of High-Frequency Activity”
and the second is “Time-frequency power”. We should be able to merge these
into a single xarray <code>DataSet</code>, which will allow us to perform operations across
both by using their shared dimensions. DataSets are kind of like collections of
DataArrays, with assumptions that the DataArrays share some metadata or coordinates.</p><p>First, we’ll rename each DataArray so that we can merge them nicely. Then, we’ll simply
use the <code>xr.merge</code> function, which tries to automatically figure out which dimensions are
shared based on their names and coordinate values.</p></div><div id="ApaOUbYrIs" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">da_tfr_baselined.name = &quot;Time Frequency Representation&quot;
da_hf_zscored_lowpass.name = &quot;Low-pass filtered HFA&quot;
ds = xr.merge([da_tfr_baselined, da_hf_zscored_lowpass])
ds</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="w-tE8YiV184kJf62625Sy" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="UGs2qwyNhH" class="relative group/block"><p>Since we’ve got a single dataset, we can grab subsets along each axis across both
DataArrays at the same time. We’ll select a subset of channels, time, and frequency bands
to visualize.</p></div><div id="xo3R34uX1p" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">ds_plt = ds.sel({&#x27;channel&#x27;: max_chan, &#x27;frequency&#x27;: slice(10, 150), &#x27;time&#x27;: slice(-.5, 2)})</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="_Jo3qJXU-dqUZuFPm46V2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Go2mfSGe02" class="relative group/block"><p>Now, we’ll plot <strong>both</strong> the spectrogram and the HFA in the same Matplotlib figure. As you
can see, these plots contain somewhat redundant information. The top plot tells us that there is
a general increase in power for high-frequencies. The bottom plot gives us the average increase in
power across the higher frequencies.</p></div><div id="kPayLC1khw" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">fig, (ax_tfr, ax_hfa) = plt.subplots(2, 1, figsize=(15, 10))
im = ds_plt[&#x27;Time Frequency Representation&#x27;].mean(&#x27;epoch&#x27;).plot.imshow(x=&#x27;time&#x27;, y=&#x27;frequency&#x27;,
                                                                       ax=ax_tfr)

ds_plt[&#x27;Low-pass filtered HFA&#x27;].mean(&#x27;epoch&#x27;).plot.line(x=&#x27;time&#x27;, ax=ax_hfa)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="o2guiLsN-cM7beMGrvSRK" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/build/f08d3a3e82c20477112b56b792308c6f.png" alt="&lt;Figure size 1080x720 with 3 Axes&gt;"/></div></div><div id="es7XvYIivs" class="relative group/block"><h2 id="wrapping-up" class="relative group"><span class="heading-text">Wrapping up</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#wrapping-up" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In all, I was pretty happy with what you can do using xarray’s <code>DataArray</code> structure.
It’s pretty nice to be able to refer to axes by their names, and to make more intelligent
selection / slicing operations using their coordinate values. Moreover, this post is just
scratching the surface for how to use this information in a way that speeds up the exploration
and analysis post.</p><p>For example, we might have sped-up some feature extraction steps by using
a distributed processing framework like <strong>Dask</strong> in the operations above. Dask integrates nicely
with xarray, and offers a lot of interesting opportunities to parallelize interactive computation.
I’ll explore that in another blog post.</p><p>Finally - the goal of this post has largely been to learn a bit more about xarray. This means I might
be totally mis-using functionality, or missing something that would have made the above process much
easier. If anybody has tips or thoughts on the code above, please do reach out!</p></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-Holdgraf_2017">Holdgraf, C. R., Rieger, J. W., Micheli, C., Martin, S., Knight, R. T., & Theunissen, F. E. (2017). Encoding and Decoding Models in Cognitive Electrophysiology. <i>Frontiers in Systems Neuroscience</i>, <i>11</i>. <a target="_blank" rel="noreferrer" href="https://doi.org/10.3389/fnsys.2017.00061">10.3389/fnsys.2017.00061</a></li></ol></div></section><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/blog/2019/2019-10-13-rust-jupyter-governance"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">2019</div>What would Rust-style governance look like in Jupyter?</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/blog/2019/2019-10-27-jupyter-governance-python"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">2019</div>What would Python-style governance look like in Jupyter?</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-TMJFFFM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-LMCDRB6W.js"/><link rel="modulepreload" href="/build/_shared/chunk-GOFUXLLW.js"/><link rel="modulepreload" href="/build/routes/$-SJYMRUNJ.js"/><script>window.__remixContext = {"url":"/blog/2019/2019-10-22-xarray-neuro","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.3.28","options":{"twitter":"choldgraf","favicon":"/build/profile-color-circle-7223b78275ad5731a04ddcbbc7c92026.png","logo_text":"Chris Holdgraf","analytics_google":"G-G5PMZM6RPE","folders":true},"nav":[{"title":"About","url":"/about"},{"title":"Projects","url":"/projects"},{"title":"Publications","url":"/publications"},{"title":"Talks","url":"/talks"},{"title":"Blog","url":"/blog"}],"actions":[{"title":"RSS","url":"https://chrisholdgraf.com/rss.xml","internal":false,"static":false}],"projects":[{"abbreviations":{"LF":"The Linux Foundation","JF":"The Jupyter Foundation","JEC":"Jupyter Executive Council","JFB":"The Jupyter Foundation Board","SSC":"Software Steering Council","OSPO":"Open Source Program Office"},"title":"Welcome","thumbnail":"/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png","authors":[{"id":"chris","nameParsed":{"literal":"Chris Holdgraf","given":"Chris","family":"Holdgraf"},"name":"Chris Holdgraf","orcid":"0000-0002-2391-0678","affiliations":["affiliations-myst-generated-uid-0","affiliations-myst-generated-uid-1"],"url":"https://chrisholdgraf.com","github":"choldgraf","twitter":"choldgraf"}],"github":"https://github.com/choldgraf/choldgraf.github.io","affiliations":[{"name":"2i2c","url":"https://2i2c.org","id":"affiliations-myst-generated-uid-0"},{"name":"Project Jupyter","url":"https://jupyter.org","id":"affiliations-myst-generated-uid-1"}],"id":"f84d70c6-7ee5-4bb9-9056-aa84134a33dd","references":{"ttw":{"url":"https://book.the-turing-way.org"}},"toc":[{"file":"index.md"},{"file":"about.md"},{"file":"projects.md"},{"file":"publications.md"},{"file":"talks.md"},{"children":[{"children":[{"pattern":"blog/2025/**{.ipynb,.md}"}],"title":"2025"},{"children":[{"pattern":"blog/2024/**{.ipynb,.md}"}],"title":"2024"},{"children":[{"pattern":"blog/2023/**{.ipynb,.md}"}],"title":"2023"},{"children":[{"pattern":"blog/2022/**{.ipynb,.md}"}],"title":"2022"},{"children":[{"pattern":"blog/2021/**{.ipynb,.md}"}],"title":"2021"},{"children":[{"pattern":"blog/2020/**{.ipynb,.md}"}],"title":"2020"},{"children":[{"pattern":"blog/2019/**{.ipynb,.md}"}],"title":"2019"},{"children":[{"pattern":"blog/2018/**{.ipynb,.md}"}],"title":"2018"},{"children":[{"pattern":"blog/2017/**{.ipynb,.md}"}],"title":"2017"},{"children":[{"pattern":"blog/2016/**{.ipynb,.md}"}],"title":"2016"},{"children":[{"pattern":"blog/2015/**{.ipynb,.md}"}],"title":"2015"}],"file":"blog.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"about","title":"About me","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects","title":"Projects","description":"","date":"","thumbnail":"/build/7d9a7172f87d448f4ed0d90adb92d4db.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"publications","title":"Publications","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"talks","title":"Talks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"blog","title":"Blog","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":2,"title":"2025"},{"slug":"blog.2025.fund-systems-not-developmend","title":"Why open source foundations try to fund systems, not development","description":"","date":"2025-05-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jec"],"level":3},{"slug":"blog.2025.jec","title":"Why I’m running for the Jupyter Executive Council","description":"","date":"2025-01-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.jupyter-org-structure","title":"The relationship between the Jupyter Executive Council, Software Steering Council, and Foundation","description":"","date":"2025-03-02","thumbnail":"/build/jupyter-foundation-s-5613751144a7be17163c803ddf9d9f88.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.more-contributors","title":"Jupyter can align the needs of its community and its foundation by enabling contribution","description":"","date":"2025-03-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2025.os-support","title":"Ways the Jupyter Foundation could support open source projects","description":"","date":"2025-02-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"level":2,"title":"2024"},{"slug":"blog.2024.blog-list","title":"Better blog lists with the MyST AST","description":"","date":"2024-11-09","thumbnail":"/build/sandbox-demo-5068bf739b4ccebce4546af8550093ca.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"slug":"blog.2024.bluesky","title":"How I’m trying to use BlueSky without getting burned again","description":"Some quick thoughts on moving from Twitter/X to BlueSky and how I'll try to use social media after being burned once by Twitter.\n","date":"2024-11-22","thumbnail":"/build/bluesky-castles-8489cda764168c75083db0e9fb75af24.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","social media"],"level":3},{"slug":"blog.2024.mystmd-with-the-blog","title":"Re-building my blog with MySTMD","description":"","date":"2024-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2024.programmatic-myst-with-jupyter","title":"Generate MyST with Jupyter and insert it into content programmatically","description":"","date":"2024-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"level":2,"title":"2023"},{"slug":"blog.2023.ai-for-good","title":"A few random opportunities in AI for Social Good","description":"","date":"2023-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.fosdem","title":"Report from FOSDEM23: beautiful chaos in a conference","description":"","date":"2023-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.social-directive","title":"A Sphinx directive for social media embeds","description":"","date":"2023-02-15","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"slug":"blog.2023.sphinx-add-extensions","title":"Bundle extensions with your Sphinx theme","description":"","date":"2023-01-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2022"},{"slug":"blog.2022.cloud-services-academia","title":"Ask Twitter: Why don’t academic researchers use cloud services?","description":"","date":"2022-09-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2022.github-2022","title":"GitHub year in review","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.install-github-from-pyproject","title":"Install dependencies from GitHub with pyproject.toml or requirements.txt","description":"","date":"2022-12-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["software development"],"level":3},{"slug":"blog.2022.jupyterlite-workshop","title":"Report from the JupyterLite workshop: WebAssembly is pretty cool","description":"","date":"2022-12-10","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","webassembly"],"level":3},{"slug":"blog.2022.matplotlib-remote-font","title":"Load and plot a remote font with Matplotlib","description":"","date":"2022-12-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["matplotlib"],"level":3},{"slug":"blog.2022.orcid-auto-update","title":"Automatically updating my publications page with ORCID and doi.org","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["scholarship","doi","orcid"],"level":3},{"slug":"blog.2022.phantom-workflows-pull-requests","title":"Fix phantom GitHub workflows in your ci-cd with protected branch rules","description":"","date":"2022-11-27","thumbnail":"/build/abdd690fd5af613c25b40bb16d6ca824.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cicd","github actions"],"level":3},{"slug":"blog.2022.precommit-autoupdate","title":"Automatically update pre-commit hook versions","description":"","date":"2022-12-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","git"],"level":3},{"slug":"blog.2022.shell-split","title":"subprocess.run can execute shell commands directly","description":"","date":"2022-11-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["shell","python"],"level":3},{"slug":"blog.2022.sphinx-custom-crossrefs","title":"Custom roles and domains in Sphinx with one line","description":"","date":"2022-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","scholarship","myst"],"level":3},{"slug":"blog.2022.sphinx-redirects-folder","title":"Automatically redirect folders in Sphinx websites","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.sphinx-update-config","title":"How to update Sphinx options during the build","description":"","date":"2022-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2021"},{"slug":"blog.2021.2021-12-18-hybrid-tutorial-prerecord","title":"Serving in two roles at once via pre-recorded tutorials","description":"","date":"2021-12-17","thumbnail":"/build/9c5f30a4a04a0ddea887b8cfbfca92ce.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["teaching"],"level":3},{"level":2,"title":"2020"},{"slug":"blog.2020.2020-01-22-rst-thoughts","title":"What do people think about rST?","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"slug":"blog.2020.organizations-help-oss-guide","title":"Contributing to open source: A short guide for organizations","description":"","date":"2020-11-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","sustainability"],"level":3},{"slug":"blog.2020.sphinx-blogging","title":"A new blog with Sphinx","description":"","date":"2020-10-10","thumbnail":"/build/sphinx-logo-5a4316ee72d502cc4b3cd0fa8e202e6c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","blogging","jupyter"],"level":3},{"slug":"blog.2020.sphinx-design-timeline","title":"Build a simple timeline with sphinx-design","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"level":2,"title":"2019"},{"slug":"blog.2019.2019-01-29-three-things-circleci","title":"Three things I love about CircleCI","description":"","date":"2019-01-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CICD","dev ops","software development"],"level":3},{"slug":"blog.2019.2019-03-16-jupyter-dev","title":"Thoughts from the Jupyter team meeting 2019","description":"","date":"2019-03-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","community"],"level":3},{"slug":"blog.2019.2019-06-25-a-few-talks","title":"A few recent talks","description":"","date":"2019-06-25","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["talks"],"level":3},{"slug":"blog.2019.2019-10-11-automating-jb","title":"Automating Jupyter Book deployments with CI/CD","description":"","date":"2019-10-11","thumbnail":"/build/jb-auto-build-659c4aa53cce6935f7836772628b2ac9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["infrastructure"],"level":3},{"slug":"blog.2019.2019-10-13-rust-jupyter-governance","title":"What would Rust-style governance look like in Jupyter?","description":"","date":"2019-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance"],"level":3},{"slug":"blog.2019.2019-10-22-xarray-neuro","title":"Analyzing intracranial electrophysiology data with xarray","description":"","date":"2019-10-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["analysis","neuroscience","xarray","open source"],"level":3},{"slug":"blog.2019.2019-10-27-jupyter-governance-python","title":"What would Python-style governance look like in Jupyter?","description":"","date":"2019-10-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance","open source"],"level":3},{"slug":"blog.2019.2019-11-11-ipynb-pandoc","title":"Testing Pandoc and Jupyter Notebooks","description":"","date":"2019-11-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","pandoc","nbconvert"],"level":3},{"level":2,"title":"2018"},{"slug":"blog.2018.circlci-github","title":"Automatically mirror a github repository with CircleCI","description":"","date":"2018-12-18","thumbnail":"/build/circleci-mirror-depl-74eb51b2629d93b8d1c9bfeb51af3698.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity","CICD"],"level":3},{"slug":"blog.2018.circle-docs","title":"Using CircleCI to preview documentation in Pull Requests","description":"","date":"2018-10-16","thumbnail":"/build/sphinx-circle-logos-7fe72c2aaaa270a75de78ff9ca722b45.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","sphinx"],"level":3},{"slug":"blog.2018.conferences-summer-2018","title":"Summer conference report back","description":"","date":"2018-08-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","conferences","communities","jupyter"],"level":3},{"slug":"blog.2018.devopsdays-sv-2018","title":"An academic scientist goes to DevOps Days","description":"","date":"2018-05-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","devops","jupyterhub","teams"],"level":3},{"slug":"blog.2018.free-labor-partners","title":"Open communities need to be partners, not sources of free labor","description":"","date":"2018-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open communities","open culture","sustainability"],"level":3},{"slug":"blog.2018.jekyllmarkdown","title":"Blogging with Jupyter Notebooks and Jekyll using nbconvert templates","description":"","date":"2018-05-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","jekyll"],"level":3},{"slug":"blog.2018.kinds-of-openness","title":"How do projects signal how “open” they are?","description":"","date":"2018-10-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","governance","community"],"level":3},{"slug":"blog.2018.makeitpop","title":"Introducing makeitpop, a tool to perceptually warp your data!\"","description":"","date":"2018-06-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python colormaps"],"level":3},{"slug":"blog.2018.my-workflow","title":"My weekly workflow","description":"","date":"2018-10-26","thumbnail":"/build/trello-board-project-77ef3950d27357e7a97fc93d2fe1e30f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity"],"level":3},{"slug":"blog.2018.rust-governance","title":"I like Rust’s governance structure","description":"","date":"2018-10-18","thumbnail":"/build/2018-10-19-rust_logo-2a04f3b729ee03dfd25f52496d4576f3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","governance","community"],"level":3},{"slug":"blog.2018.sphinx-copy-buttons","title":"Adding copy buttons to code blocks in Sphinx","description":"","date":"2018-07-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","sphinx","documentation"],"level":3},{"level":2,"title":"2017"},{"slug":"blog.2017.2017-01-04-matplotlib-cycles","title":"Matplotlib Cyclers are Great","description":"","date":"2017-01-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations"],"level":3},{"slug":"blog.2017.2017-03-16-dates-in-python","title":"Dates in python","description":"","date":"2017-03-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"slug":"blog.2017.2017-11-02-dates-multiple-plots","title":"Combining dates with analysis visualization in python","description":"","date":"2017-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"level":2,"title":"2016"},{"slug":"blog.2016.2016-07-02-fft-time","title":"The beauty of computational efficiency","description":"","date":"2016-07-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","computation","efficiency","fft"],"level":3},{"slug":"blog.2016.2016-07-08-voting-randomness","title":"Could Brexit have happened by chance?","description":"","date":"2016-07-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","voting","statistics","computation","fft"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016","title":"5 things I learned at SciPy","description":"","date":"2016-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","programming","conferences"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016-1","title":"1. Scientific conferences can be fun","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2016.2016-11-30-funnel-plots","title":"Visualizing publication bias","description":"","date":"2016-11-30","thumbnail":"/build/funnel_plot_no_dists-19972fc44f9d3c2d95384c9da4a10562.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","funnel plots","open science","visualizations","simulations"],"level":3},{"slug":"blog.2016.2016-12-19-biorxiv-neuro","title":"The bleeding edge of publishing, Scraping publication amounts at biorxiv","description":"","date":"2016-12-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","web scraping","preprints"],"level":3},{"slug":"blog.2016.2016-12-23-christmas-ecog-plot","title":"Brainy Jingle Bells","description":"","date":"2016-12-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","brains","holidays"],"level":3},{"level":2,"title":"2015"},{"slug":"blog.2015.2015-05-27-coherence-correlation","title":"Coherence vs. Correlation - a simple simulation","description":"","date":"2015-05-27","thumbnail":"/build/eeg_coh-7a3ec59068b2ba221f0e4941450da5c9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","timeseries","correlation"],"level":3},{"slug":"blog.2015.2015-08-30-craigslist-scrape","title":"Scraping craigslist","description":"","date":"2015-08-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming"],"level":3},{"slug":"blog.2015.2015-09-27-craigslist-data-analysis","title":"Craigslist data analysis","description":"","date":"2015-09-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","scraping","data analysis","visualization"],"level":3},{"slug":"blog.2015.2015-10-29-nih-grant-analysis","title":"NIH grant analysis","description":"","date":"2015-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","statistics","visualization","grants"],"level":3}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":2,"myst":"1.3.28","options":{"twitter":"choldgraf","favicon":"/build/profile-color-circle-7223b78275ad5731a04ddcbbc7c92026.png","logo_text":"Chris Holdgraf","analytics_google":"G-G5PMZM6RPE","folders":true},"nav":[{"title":"About","url":"/about"},{"title":"Projects","url":"/projects"},{"title":"Publications","url":"/publications"},{"title":"Talks","url":"/talks"},{"title":"Blog","url":"/blog"}],"actions":[{"title":"RSS","url":"https://chrisholdgraf.com/rss.xml","internal":false,"static":false}],"projects":[{"abbreviations":{"LF":"The Linux Foundation","JF":"The Jupyter Foundation","JEC":"Jupyter Executive Council","JFB":"The Jupyter Foundation Board","SSC":"Software Steering Council","OSPO":"Open Source Program Office"},"title":"Welcome","thumbnail":"/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png","authors":[{"id":"chris","nameParsed":{"literal":"Chris Holdgraf","given":"Chris","family":"Holdgraf"},"name":"Chris Holdgraf","orcid":"0000-0002-2391-0678","affiliations":["affiliations-myst-generated-uid-0","affiliations-myst-generated-uid-1"],"url":"https://chrisholdgraf.com","github":"choldgraf","twitter":"choldgraf"}],"github":"https://github.com/choldgraf/choldgraf.github.io","affiliations":[{"name":"2i2c","url":"https://2i2c.org","id":"affiliations-myst-generated-uid-0"},{"name":"Project Jupyter","url":"https://jupyter.org","id":"affiliations-myst-generated-uid-1"}],"id":"f84d70c6-7ee5-4bb9-9056-aa84134a33dd","references":{"ttw":{"url":"https://book.the-turing-way.org"}},"toc":[{"file":"index.md"},{"file":"about.md"},{"file":"projects.md"},{"file":"publications.md"},{"file":"talks.md"},{"children":[{"children":[{"pattern":"blog/2025/**{.ipynb,.md}"}],"title":"2025"},{"children":[{"pattern":"blog/2024/**{.ipynb,.md}"}],"title":"2024"},{"children":[{"pattern":"blog/2023/**{.ipynb,.md}"}],"title":"2023"},{"children":[{"pattern":"blog/2022/**{.ipynb,.md}"}],"title":"2022"},{"children":[{"pattern":"blog/2021/**{.ipynb,.md}"}],"title":"2021"},{"children":[{"pattern":"blog/2020/**{.ipynb,.md}"}],"title":"2020"},{"children":[{"pattern":"blog/2019/**{.ipynb,.md}"}],"title":"2019"},{"children":[{"pattern":"blog/2018/**{.ipynb,.md}"}],"title":"2018"},{"children":[{"pattern":"blog/2017/**{.ipynb,.md}"}],"title":"2017"},{"children":[{"pattern":"blog/2016/**{.ipynb,.md}"}],"title":"2016"},{"children":[{"pattern":"blog/2015/**{.ipynb,.md}"}],"title":"2015"}],"file":"blog.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"about","title":"About me","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects","title":"Projects","description":"","date":"","thumbnail":"/build/7d9a7172f87d448f4ed0d90adb92d4db.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"publications","title":"Publications","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"talks","title":"Talks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"blog","title":"Blog","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":2,"title":"2025"},{"slug":"blog.2025.fund-systems-not-developmend","title":"Why open source foundations try to fund systems, not development","description":"","date":"2025-05-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jec"],"level":3},{"slug":"blog.2025.jec","title":"Why I’m running for the Jupyter Executive Council","description":"","date":"2025-01-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.jupyter-org-structure","title":"The relationship between the Jupyter Executive Council, Software Steering Council, and Foundation","description":"","date":"2025-03-02","thumbnail":"/build/jupyter-foundation-s-5613751144a7be17163c803ddf9d9f88.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.more-contributors","title":"Jupyter can align the needs of its community and its foundation by enabling contribution","description":"","date":"2025-03-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2025.os-support","title":"Ways the Jupyter Foundation could support open source projects","description":"","date":"2025-02-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"level":2,"title":"2024"},{"slug":"blog.2024.blog-list","title":"Better blog lists with the MyST AST","description":"","date":"2024-11-09","thumbnail":"/build/sandbox-demo-5068bf739b4ccebce4546af8550093ca.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"slug":"blog.2024.bluesky","title":"How I’m trying to use BlueSky without getting burned again","description":"Some quick thoughts on moving from Twitter/X to BlueSky and how I'll try to use social media after being burned once by Twitter.\n","date":"2024-11-22","thumbnail":"/build/bluesky-castles-8489cda764168c75083db0e9fb75af24.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","social media"],"level":3},{"slug":"blog.2024.mystmd-with-the-blog","title":"Re-building my blog with MySTMD","description":"","date":"2024-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2024.programmatic-myst-with-jupyter","title":"Generate MyST with Jupyter and insert it into content programmatically","description":"","date":"2024-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"level":2,"title":"2023"},{"slug":"blog.2023.ai-for-good","title":"A few random opportunities in AI for Social Good","description":"","date":"2023-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.fosdem","title":"Report from FOSDEM23: beautiful chaos in a conference","description":"","date":"2023-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.social-directive","title":"A Sphinx directive for social media embeds","description":"","date":"2023-02-15","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"slug":"blog.2023.sphinx-add-extensions","title":"Bundle extensions with your Sphinx theme","description":"","date":"2023-01-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2022"},{"slug":"blog.2022.cloud-services-academia","title":"Ask Twitter: Why don’t academic researchers use cloud services?","description":"","date":"2022-09-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2022.github-2022","title":"GitHub year in review","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.install-github-from-pyproject","title":"Install dependencies from GitHub with pyproject.toml or requirements.txt","description":"","date":"2022-12-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["software development"],"level":3},{"slug":"blog.2022.jupyterlite-workshop","title":"Report from the JupyterLite workshop: WebAssembly is pretty cool","description":"","date":"2022-12-10","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","webassembly"],"level":3},{"slug":"blog.2022.matplotlib-remote-font","title":"Load and plot a remote font with Matplotlib","description":"","date":"2022-12-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["matplotlib"],"level":3},{"slug":"blog.2022.orcid-auto-update","title":"Automatically updating my publications page with ORCID and doi.org","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["scholarship","doi","orcid"],"level":3},{"slug":"blog.2022.phantom-workflows-pull-requests","title":"Fix phantom GitHub workflows in your ci-cd with protected branch rules","description":"","date":"2022-11-27","thumbnail":"/build/abdd690fd5af613c25b40bb16d6ca824.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cicd","github actions"],"level":3},{"slug":"blog.2022.precommit-autoupdate","title":"Automatically update pre-commit hook versions","description":"","date":"2022-12-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","git"],"level":3},{"slug":"blog.2022.shell-split","title":"subprocess.run can execute shell commands directly","description":"","date":"2022-11-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["shell","python"],"level":3},{"slug":"blog.2022.sphinx-custom-crossrefs","title":"Custom roles and domains in Sphinx with one line","description":"","date":"2022-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","scholarship","myst"],"level":3},{"slug":"blog.2022.sphinx-redirects-folder","title":"Automatically redirect folders in Sphinx websites","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.sphinx-update-config","title":"How to update Sphinx options during the build","description":"","date":"2022-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2021"},{"slug":"blog.2021.2021-12-18-hybrid-tutorial-prerecord","title":"Serving in two roles at once via pre-recorded tutorials","description":"","date":"2021-12-17","thumbnail":"/build/9c5f30a4a04a0ddea887b8cfbfca92ce.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["teaching"],"level":3},{"level":2,"title":"2020"},{"slug":"blog.2020.2020-01-22-rst-thoughts","title":"What do people think about rST?","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"slug":"blog.2020.organizations-help-oss-guide","title":"Contributing to open source: A short guide for organizations","description":"","date":"2020-11-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","sustainability"],"level":3},{"slug":"blog.2020.sphinx-blogging","title":"A new blog with Sphinx","description":"","date":"2020-10-10","thumbnail":"/build/sphinx-logo-5a4316ee72d502cc4b3cd0fa8e202e6c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","blogging","jupyter"],"level":3},{"slug":"blog.2020.sphinx-design-timeline","title":"Build a simple timeline with sphinx-design","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"level":2,"title":"2019"},{"slug":"blog.2019.2019-01-29-three-things-circleci","title":"Three things I love about CircleCI","description":"","date":"2019-01-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CICD","dev ops","software development"],"level":3},{"slug":"blog.2019.2019-03-16-jupyter-dev","title":"Thoughts from the Jupyter team meeting 2019","description":"","date":"2019-03-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","community"],"level":3},{"slug":"blog.2019.2019-06-25-a-few-talks","title":"A few recent talks","description":"","date":"2019-06-25","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["talks"],"level":3},{"slug":"blog.2019.2019-10-11-automating-jb","title":"Automating Jupyter Book deployments with CI/CD","description":"","date":"2019-10-11","thumbnail":"/build/jb-auto-build-659c4aa53cce6935f7836772628b2ac9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["infrastructure"],"level":3},{"slug":"blog.2019.2019-10-13-rust-jupyter-governance","title":"What would Rust-style governance look like in Jupyter?","description":"","date":"2019-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance"],"level":3},{"slug":"blog.2019.2019-10-22-xarray-neuro","title":"Analyzing intracranial electrophysiology data with xarray","description":"","date":"2019-10-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["analysis","neuroscience","xarray","open source"],"level":3},{"slug":"blog.2019.2019-10-27-jupyter-governance-python","title":"What would Python-style governance look like in Jupyter?","description":"","date":"2019-10-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance","open source"],"level":3},{"slug":"blog.2019.2019-11-11-ipynb-pandoc","title":"Testing Pandoc and Jupyter Notebooks","description":"","date":"2019-11-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","pandoc","nbconvert"],"level":3},{"level":2,"title":"2018"},{"slug":"blog.2018.circlci-github","title":"Automatically mirror a github repository with CircleCI","description":"","date":"2018-12-18","thumbnail":"/build/circleci-mirror-depl-74eb51b2629d93b8d1c9bfeb51af3698.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity","CICD"],"level":3},{"slug":"blog.2018.circle-docs","title":"Using CircleCI to preview documentation in Pull Requests","description":"","date":"2018-10-16","thumbnail":"/build/sphinx-circle-logos-7fe72c2aaaa270a75de78ff9ca722b45.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","sphinx"],"level":3},{"slug":"blog.2018.conferences-summer-2018","title":"Summer conference report back","description":"","date":"2018-08-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","conferences","communities","jupyter"],"level":3},{"slug":"blog.2018.devopsdays-sv-2018","title":"An academic scientist goes to DevOps Days","description":"","date":"2018-05-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","devops","jupyterhub","teams"],"level":3},{"slug":"blog.2018.free-labor-partners","title":"Open communities need to be partners, not sources of free labor","description":"","date":"2018-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open communities","open culture","sustainability"],"level":3},{"slug":"blog.2018.jekyllmarkdown","title":"Blogging with Jupyter Notebooks and Jekyll using nbconvert templates","description":"","date":"2018-05-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","jekyll"],"level":3},{"slug":"blog.2018.kinds-of-openness","title":"How do projects signal how “open” they are?","description":"","date":"2018-10-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","governance","community"],"level":3},{"slug":"blog.2018.makeitpop","title":"Introducing makeitpop, a tool to perceptually warp your data!\"","description":"","date":"2018-06-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python colormaps"],"level":3},{"slug":"blog.2018.my-workflow","title":"My weekly workflow","description":"","date":"2018-10-26","thumbnail":"/build/trello-board-project-77ef3950d27357e7a97fc93d2fe1e30f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity"],"level":3},{"slug":"blog.2018.rust-governance","title":"I like Rust’s governance structure","description":"","date":"2018-10-18","thumbnail":"/build/2018-10-19-rust_logo-2a04f3b729ee03dfd25f52496d4576f3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","governance","community"],"level":3},{"slug":"blog.2018.sphinx-copy-buttons","title":"Adding copy buttons to code blocks in Sphinx","description":"","date":"2018-07-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","sphinx","documentation"],"level":3},{"level":2,"title":"2017"},{"slug":"blog.2017.2017-01-04-matplotlib-cycles","title":"Matplotlib Cyclers are Great","description":"","date":"2017-01-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations"],"level":3},{"slug":"blog.2017.2017-03-16-dates-in-python","title":"Dates in python","description":"","date":"2017-03-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"slug":"blog.2017.2017-11-02-dates-multiple-plots","title":"Combining dates with analysis visualization in python","description":"","date":"2017-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"level":2,"title":"2016"},{"slug":"blog.2016.2016-07-02-fft-time","title":"The beauty of computational efficiency","description":"","date":"2016-07-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","computation","efficiency","fft"],"level":3},{"slug":"blog.2016.2016-07-08-voting-randomness","title":"Could Brexit have happened by chance?","description":"","date":"2016-07-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","voting","statistics","computation","fft"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016","title":"5 things I learned at SciPy","description":"","date":"2016-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","programming","conferences"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016-1","title":"1. Scientific conferences can be fun","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2016.2016-11-30-funnel-plots","title":"Visualizing publication bias","description":"","date":"2016-11-30","thumbnail":"/build/funnel_plot_no_dists-19972fc44f9d3c2d95384c9da4a10562.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","funnel plots","open science","visualizations","simulations"],"level":3},{"slug":"blog.2016.2016-12-19-biorxiv-neuro","title":"The bleeding edge of publishing, Scraping publication amounts at biorxiv","description":"","date":"2016-12-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","web scraping","preprints"],"level":3},{"slug":"blog.2016.2016-12-23-christmas-ecog-plot","title":"Brainy Jingle Bells","description":"","date":"2016-12-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","brains","holidays"],"level":3},{"level":2,"title":"2015"},{"slug":"blog.2015.2015-05-27-coherence-correlation","title":"Coherence vs. Correlation - a simple simulation","description":"","date":"2015-05-27","thumbnail":"/build/eeg_coh-7a3ec59068b2ba221f0e4941450da5c9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","timeseries","correlation"],"level":3},{"slug":"blog.2015.2015-08-30-craigslist-scrape","title":"Scraping craigslist","description":"","date":"2015-08-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming"],"level":3},{"slug":"blog.2015.2015-09-27-craigslist-data-analysis","title":"Craigslist data analysis","description":"","date":"2015-09-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","scraping","data analysis","visualization"],"level":3},{"slug":"blog.2015.2015-10-29-nih-grant-analysis","title":"NIH grant analysis","description":"","date":"2015-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","statistics","visualization","grants"],"level":3}]}]},"page":{"version":2,"kind":"Notebook","sha256":"a87840b6b6f9d5b677027ab959b5f9f4f77873f0c340c5eb8c82d7587d065eee","slug":"blog.2019.2019-10-22-xarray-neuro","location":"/blog/2019/2019-10-22-xarray-neuro.ipynb","dependencies":[],"frontmatter":{"title":"Analyzing intracranial electrophysiology data with xarray","tags":["analysis","neuroscience","xarray","open source"],"date":"2019-10-22","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"content_includes_title":false,"authors":[{"id":"chris","nameParsed":{"literal":"Chris Holdgraf","given":"Chris","family":"Holdgraf"},"name":"Chris Holdgraf","orcid":"0000-0002-2391-0678","affiliations":["affiliations-myst-generated-uid-0","affiliations-myst-generated-uid-1"],"url":"https://chrisholdgraf.com","github":"choldgraf","twitter":"choldgraf"}],"github":"https://github.com/choldgraf/choldgraf.github.io","affiliations":[{"name":"2i2c","url":"https://2i2c.org","id":"affiliations-myst-generated-uid-0"},{"name":"Project Jupyter","url":"https://jupyter.org","id":"affiliations-myst-generated-uid-1"}],"abbreviations":{"LF":"The Linux Foundation","JF":"The Jupyter Foundation","JEC":"Jupyter Executive Council","JFB":"The Jupyter Foundation Board","SSC":"Software Steering Council","OSPO":"Open Source Program Office"},"numbering":{"title":{"offset":2}},"edit_url":"https://github.com/choldgraf/choldgraf.github.io/blob/main/blog/2019/2019-10-22-xarray-neuro.ipynb","exports":[{"format":"ipynb","filename":"2019-10-22-xarray-neuro.ipynb","url":"/build/2019-10-22-xarray-ne-a68bcd80b09e0745b0957087fe93ffa9.ipynb"}]},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0},"date":"2019-10-22","redirect":"xarray-explore-ieeg","tags":["analysis","neuroscience","xarray","open source"]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":29,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Over the last few years, it has been exciting to see the xarray project evolve,\nadd new functionality, and mature. This post is an attempt at\ngiving xarray another visit to see how it could integrate into electrophysiology\nworkflows.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"QZnzZJDn4t"}],"key":"phDLT4c0Qo"},{"type":"heading","depth":3,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"A quick background on our data","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"vYJIyjJASZ"}],"identifier":"a-quick-background-on-our-data","label":"A quick background on our data","html_id":"a-quick-background-on-our-data","implicit":true,"key":"MVKEXOT6js"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"It is common in neuroscience to ask individuals to perform a task over and over again. You record\nthe activity in the brain each time they perform the task (called an “epoch” or a “trial”).\nTime is recorded relative to some ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"ln03tLOqiT"},{"type":"emphasis","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"onset","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"oTzCOtMwc9"}],"key":"iCX6YB2hCi"},{"type":"text","value":" when the task begins. That is ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"mWnlLBgAWm"},{"type":"inlineCode","value":"t==0","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"FBhoGGopGx"},{"type":"text","value":". The result\nis usually a matrix of ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"FZtKTCXlvO"},{"type":"inlineCode","value":"epochs x channejupyls x time","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"vFHLFaGUsO"},{"type":"text","value":". You can do a lot of stuff with this\ndata, but our task in this paper is to detect changes in neural activity at trial onset (","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"dcu1QiwiYg"},{"type":"inlineCode","value":"t==0","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"XIVVuuodMh"},{"type":"text","value":").","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"gqyz2PFTNp"}],"key":"QCn0m5g1GW"},{"type":"paragraph","position":{"start":{"line":42,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"In our case, we’ve got a small dataset from ","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"NpLEYIniqG"},{"type":"cite","url":"https://www.frontiersin.org/articles/10.3389/fnsys.2017.00061/full","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"an old paper of mine","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"U5nHkSfkPV"}],"kind":"narrative","label":"Holdgraf_2017","identifier":"https://www.frontiersin.org/articles/10.3389/fnsys.2017.00061/full","enumerator":"1","key":"tMGc6ndqfL"},{"type":"text","value":".\nThe repository contains\nseveral tutorial notebooks and sample data to describe predictive modeling\nin cognitive neuroscience. ","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"IUIgPEKXxh"},{"type":"link","url":"https://github.com/choldgraf/paper-encoding_decoding_electrophysiology","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"You can find the repository here","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"dAtIVAOdN7"}],"urlSource":"https://github.com/choldgraf/paper-encoding_decoding_electrophysiology","error":true,"key":"GkI40D5Uu4"},{"type":"text","value":". The task that individuals were performing was passively\nlistening to spoken sentences through a speaker. While they did this, we recorded electrical\nactivity at the surface of their brain (these were surgical patients, and had implanted electrodes\nunder their scalp).","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"W6OyyvXlE0"}],"key":"UhZGyxB93L"},{"type":"paragraph","position":{"start":{"line":50,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"In the ","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"HNJ2v6IhxV"},{"type":"link","url":"https://github.com/choldgraf/paper-encoding_decoding_electrophysiology/blob/master/notebooks/FeatureExtraction.ipynb","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"Feature Extraction","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"hIs4hgJZf4"}],"urlSource":"https://github.com/choldgraf/paper-encoding_decoding_electrophysiology/blob/master/notebooks/FeatureExtraction.ipynb","data":{"kind":"file","org":"choldgraf","repo":"paper-encoding_decoding_electrophysiology","reference":"master","file":"notebooks/FeatureExtraction.ipynb","raw":"https://raw.githubusercontent.com/choldgraf/paper-encoding_decoding_electrophysiology/master/notebooks/FeatureExtraction.ipynb"},"internal":false,"protocol":"github","key":"sjMT5jd9in"},{"type":"text","value":" notebook,\nI covered how to do some simple data manipulation and feature extraction with\ntimeseries analysis. Let’s try to re-create some of the main steps in that tutorial,\nbut now using xarray as an in-memory structure for our data.","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"EPglrCwmg6"}],"key":"Bnq0Qa1f3D"}],"key":"J3qCiQ7CGq"},{"type":"block","kind":"notebook-content","data":{"tags":["popout"]},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yB1GmLedaI"}],"key":"ZboTkWg4dG"},{"type":"text","value":": The goal here is to learn a bit about xarray moreso than to discuss\necog modeling, so I’ll spend more time talking about my thoughts on the various\nfunctions/methods/etc in Xarray than talking about neuroscience.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iPzwAe4CgS"}],"key":"uemJW07wjp"}],"visibility":"show","key":"VpZliJjwcW"},{"type":"block","kind":"notebook-content","data":{"toc-hr-collapsed":false},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this post, we’ll perform a few common processing and extraction steps.\nThe goal is to do a few munging operations that require manipulating data\nand visualizing simple statistics.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XDT2qQdpwQ"}],"key":"Wqr3dEDRx9"}],"key":"lB9myF0Oh9"},{"type":"block","kind":"notebook-code","data":{"tags":["hide_input"]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Imports we'll use later\nimport mne\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom download import download\nimport os\nfrom sklearn.preprocessing import scale\nimport xarray as xr\nxr.set_options(display_style=\"html\")\n\nimport warnings\nwarnings.simplefilter('ignore')\n%matplotlib inline","visibility":"show","key":"nLENRTxUnD"},{"type":"output","id":"KkL8_nTupj_PlvPPsU2_I","data":[],"visibility":"show","key":"Ts1a47onwM"}],"visibility":"show","key":"Pesr85X6yc"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We’ll load the data from my GitHub repository (probably not the most efficient\nway to store or retrieve the data, but hey, this was 3 years ago :-) ).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KmSKCgkl44"}],"key":"zGKnIP3pLn"}],"key":"N9suYfbbUM"},{"type":"block","kind":"notebook-code","data":{"tags":["remove_output"]},"children":[{"type":"code","lang":"python","executable":true,"value":"url_epochs = \"https://github.com/choldgraf/paper-encoding_decoding_electrophysiology/blob/master/raw_data/ecog-epo.fif?raw=true\"\n\npath_data = download(url_epochs, './ecog-epo.fif', replace=True)\necog = mne.read_epochs(path_data, preload=True)\nos.remove(path_data)","visibility":"show","key":"s42erNIywP"},{"type":"output","id":"2GYrk5SXLCATNe21dHcnU","data":[{"name":"stderr","output_type":"stream","text":"file_sizes:   0%|                                   | 0.00/8.36M [00:00\u003c?, ?B/s]"},{"name":"stdout","output_type":"stream","text":"Downloading data from https://raw.githubusercontent.com/choldgraf/paper-encoding_decoding_electrophysiology/master/raw_data/ecog-epo.fif?raw=true (8.0 MB)\n\n"},{"name":"stderr","output_type":"stream","text":"file_sizes: 100%|██████████████████████████| 8.36M/8.36M [00:00\u003c00:00, 12.5MB/s]"},{"name":"stdout","output_type":"stream","text":"Successfully downloaded file to ./ecog-epo.fif\nReading ./ecog-epo.fif ...\n"},{"name":"stderr","output_type":"stream","text":"\n"},{"name":"stdout","output_type":"stream","text":"Isotrak not found\n    Found the data of interest:\n        t =   -1500.00 ...    5996.67 ms\n        0 CTF compensation matrices available\n29 matching events found\nNo baseline correction applied\nNot setting metadata\n0 projection items activated\n"}],"visibility":"show","key":"s8IKe3LAQD"}],"visibility":"show","key":"eMdVrFhUvq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Here’s what the raw data looks like - each horizontal line is electrical activity\nin a channel over time. The faint vertical green lines show the onset of\neach trial (they are concatenated together, but in reality there’s a bit of time\nbetween trials). This will be one of the last times we use MNE hopefully.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j8jaITXHqe"}],"key":"eDAIuaAR5P"}],"key":"dsPDb20t1i"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"_ = ecog.plot(scalings='auto', n_epochs=5, n_channels=10)","key":"AcN09lGyao"},{"type":"output","id":"UblpdiuEFMtUZ4zjUlULL","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"fc24837c97da2d130f181274745e4ae0","path":"/build/fc24837c97da2d130f181274745e4ae0.png"},"text/plain":{"content":"\u003cFigure size 480x320 with 5 Axes\u003e","content_type":"text/plain"}}}],"key":"yZiNTco7Rh"}],"key":"ng3jM1IGu0"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Converting to xarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tz5u8er80W"}],"identifier":"converting-to-xarray","label":"Converting to xarray","html_id":"converting-to-xarray","implicit":true,"key":"G2TioZdsOm"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"First off, we’ll define a helper function that\nconverts the MNE Epochs object into an xarray DataArray object.\nDataArrays provide an N-Dimensional representation of data, but with\nthe option to include a lot of extra metadata.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HtgY9pJQDd"}],"key":"HkbyG1oCUO"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"DataArrays are useful because you can include information\n","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"nDjT1joMmM"},{"type":"emphasis","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"about each dimension","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"PXcXrrvGiP"}],"key":"XBWiPGaSh2"},{"type":"text","value":" of the data. For example, we can tell our\nDataArray the name, values, and units of each dimension. In this case,\nin our case one dimension is “time” so we can label it as such.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"zv1tzeWYDl"}],"key":"I24MAxv2KY"}],"key":"iRAwQjTlh4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def epochs_to_dataarray(epochs):\n    \"\"\"A simple function to convert an Epochs object to DataArray\"\"\"\n    da = xr.DataArray(\n    epochs._data,\n    dims=['epoch', 'channel', 'time'],\n    coords={\n        'time': ecog.times,\n        'channel': ecog.ch_names,\n        'epoch': range(ecog._data.shape[0])\n    },\n    name='Sample dataset',\n    attrs=dict(ecog.info)\n    )\n    return da","key":"LfhKkPsYfL"},{"type":"output","id":"M1u-BnHapPiQMGEoUj4I_","data":[],"key":"PR1bvnmF7C"}],"key":"wzUZ2KUQ1v"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Just look at all the metadata that we were able to pack into the DataArray.\nAlmost all of MNE’s metadata fit nicely into ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xk9oz1YmX5"},{"type":"inlineCode","value":".attrs","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MvW9Cff51Z"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JOfF4qgpdH"}],"key":"uk3VhTEPvQ"}],"key":"Yj0P25U9Ne"},{"type":"block","kind":"notebook-code","data":{"tags":["hide_output"]},"children":[{"type":"code","lang":"python","executable":true,"value":"# There's quite a lot of output, so keep scrolling down!\nda = epochs_to_dataarray(ecog)\nda","visibility":"show","key":"zC1N4fJ4kf"},{"type":"output","id":"6KKQ9CQ19l72uTsS2fMuB","data":[{"output_type":"execute_result","execution_count":22,"metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"a760fe95ea5bfe6bf4775eed437092ce","path":"/build/a760fe95ea5bfe6bf4775eed437092ce.html"},"text/plain":{"content":"\u003cxarray.DataArray 'Sample dataset' (epoch: 29, channel: 32, time: 2250)\u003e\narray([[[-118.10999298, -121.30046844, -117.64116669, ...,\n           20.78869057,   11.38018703,    8.12319088],\n        [-126.95540619, -120.84265137, -105.75999451, ...,\n           25.57149315,   28.6223793 ,   24.82316971],\n        [ -28.1061306 ,  -16.39686775,  -21.64873505, ...,\n          -31.78049469,  -24.28160286,  -25.21776772],\n        ...,\n        [  18.55451965,   22.87419701,   25.66038895, ...,\n           25.84903336,   19.71798515,   14.92882633],\n        [ -44.79590607,  -49.5848465 ,  -52.08906555, ...,\n          -48.92469025,  -54.11177826,  -60.23026276],\n        [-105.09076691, -108.88887024, -113.57571411, ...,\n           -3.28264022,    5.5660615 ,   13.18798733]],\n\n       [[  20.84839821,   18.30262566,   20.12442017, ...,\n          -19.40711594,  -18.51371574,  -20.21596718],\n        [  18.0386982 ,    5.35804272,   -6.45382166, ...,\n          -42.1801033 ,  -44.59093857,  -47.80654144],\n        [  76.62892914,   73.66176605,   64.21563721, ...,\n          -12.31007576,  -21.26686478,  -26.83379555],\n        ...,\n        [  58.06867599,   53.49727631,   51.89107895, ...,\n           42.84626007,   52.36317062,   55.75439453],\n        [ -24.79452324,  -18.58691406,   -8.12459183, ...,\n          -45.95447159,  -42.66623306,  -41.06335449],\n        [-110.1750946 , -101.40830994,  -88.24209595, ...,\n          -26.7741375 ,  -32.31249619,  -37.07465744]],\n\n       [[  44.85819626,   57.10462952,   68.87900543, ...,\n           13.73396015,   28.33650208,   40.76254654],\n        [  10.10721684,   19.94246101,   31.81379509, ...,\n          120.01114655,  119.50100708,  128.0358429 ],\n        [ -96.35434723,  -89.9883194 ,  -72.41400909, ...,\n          140.28143311,  131.52635193,  133.30158997],\n        ...,\n        [   1.81244755,   -1.55214143,   -2.54425907, ...,\n          -30.9526062 ,  -31.50832367,  -32.25312042],\n        [  44.95462799,   38.7992363 ,   33.4192009 , ...,\n           64.5262146 ,   62.74245834,   61.11261368],\n        [ -37.66891861,  -37.9514122 ,  -40.97248077, ...,\n           61.204319  ,   58.57411194,   56.27007675]],\n\n       ...,\n\n       [[  88.75709534,   83.42398071,   76.10377502, ...,\n          -23.7650528 ,  -23.43914986,  -19.55894852],\n        [  63.89505005,   63.79450226,   61.43893433, ...,\n          -54.35200119,  -59.907547  ,  -69.36830139],\n        [  39.31270599,   46.15828705,   51.12403107, ...,\n          -30.19447899,  -27.1382637 ,  -19.75760651],\n        ...,\n        [  -2.09485602,  -13.05238819,  -19.73264503, ...,\n          150.31195068,  129.28895569,  114.28322601],\n        [-142.40054321, -142.72599792, -140.20773315, ...,\n           90.81705475,   82.73035431,   77.06429291],\n        [-161.34713745, -160.04364014, -151.092453  , ...,\n          238.87109375,  230.41633606,  222.64045715]],\n\n       [[  67.85353088,   72.97834778,   70.99682617, ...,\n           99.13801575,   95.14775085,   86.59616089],\n        [ 169.86994934,  172.12055969,  173.22143555, ...,\n          132.95147705,  135.66346741,  141.64862061],\n        [  80.4973526 ,   77.63601685,   73.43898773, ...,\n           91.37036896,   84.76886749,   82.48825836],\n        ...,\n        [ -13.24606895,   -8.65564728,    6.53395557, ...,\n         -105.62326813, -104.58720398, -107.99065399],\n        [  22.20972443,   49.33536148,   85.349823  , ...,\n         -103.54721069, -102.84375   , -104.26371002],\n        [ -33.03855133,   -9.5574255 ,   10.97984695, ...,\n         -148.20103455, -148.95999146, -154.4241333 ]],\n\n       [[ -98.52385712,  -99.22042847,  -99.56749725, ...,\n           49.72173309,   41.6667099 ,   31.01161194],\n        [ -70.90259552,  -66.83739471,  -68.66448975, ...,\n           35.73180008,   33.55708694,   28.1260643 ],\n        [ -29.78354645,  -34.5358963 ,  -40.23687363, ...,\n          -39.39603043,  -42.75005341,  -50.70994186],\n        ...,\n        [ 110.57292175,  103.35498047,   95.09171295, ...,\n         -162.01602173, -164.45585632, -168.76620483],\n        [  38.4355278 ,   39.19929504,   43.87767792, ...,\n         -108.41282654, -106.09828949, -103.17415619],\n        [  98.9158783 ,  105.16780853,  116.0725174 , ...,\n         -105.856987  , -105.39962769, -102.4755249 ]]])\nCoordinates:\n  * time     (time) float64 -1.5 -1.497 -1.493 -1.49 ... 5.987 5.99 5.993 5.997\n  * channel  (channel) \u003cU5 'ch_0' 'ch_1' 'ch_2' ... 'ch_29' 'ch_30' 'ch_31'\n  * epoch    (epoch) int64 0 1 2 3 4 5 6 7 8 9 ... 19 20 21 22 23 24 25 26 27 28\nAttributes:\n    file_id:             {'version': 65539, 'machid': array([808661043, 80866...\n    events:              []\n    hpi_results:         []\n    hpi_meas:            []\n    subject_info:        None\n    device_info:         None\n    helium_info:         None\n    hpi_subsystem:       None\n    proc_history:        []\n    meas_id:             {'version': 65539, 'machid': array([808661043, 80866...\n    experimenter:        None\n    description:         None\n    proj_id:             None\n    proj_name:           None\n    meas_date:           (0, 0)\n    utc_offset:          None\n    sfreq:               300.0\n    highpass:            0.0\n    lowpass:             500.0\n    line_freq:           None\n    gantry_angle:        None\n    chs:                 [{'scanno': 1, 'logno': 1, 'kind': 902, 'range': 1.0...\n    dev_head_t:          \u003cTransform  |  MEG device-\u003ehead\u003e\\n[[1. 0. 0. 0.]\\n [...\n    ctf_head_t:          None\n    dev_ctf_t:           None\n    dig:                 []\n    bads:                []\n    ch_names:            ['ch_0', 'ch_1', 'ch_2', 'ch_3', 'ch_4', 'ch_5', 'ch...\n    nchan:               32\n    projs:               []\n    comps:               []\n    acq_pars:            None\n    acq_stim:            None\n    custom_ref_applied:  False\n    xplotter_layout:     None\n    kit_system_id:       None","content_type":"text/plain"}}}],"visibility":"show","key":"w75JuESEFc"}],"visibility":"show","key":"bPL5yqbKHX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The data consists of many trials, channels, and timepoints.\nLet’s start by selecting a time region within each trial that\nwe can visualize more cleanly.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"th771Yc0hc"}],"key":"CeUNQ5PFLk"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Subsetting out data with ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fsq2PF3iVJ"},{"type":"inlineCode","value":"da.sel","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lVWLCPUUnv"}],"identifier":"subsetting-out-data-with-da-sel","label":"Subsetting out data with da.sel","html_id":"subsetting-out-data-with-da-sel","implicit":true,"key":"XP3FmCfVIe"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"In xarray, we select items with the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UqdJSZBTvU"},{"type":"inlineCode","value":"sel","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"XoHwxQ5rPx"},{"type":"text","value":" and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Z2NhF04zo7"},{"type":"inlineCode","value":"isel","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UufPFoo1hf"},{"type":"text","value":" method. This\nbehaves kind of like the pandas ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"wrxa8vCxdU"},{"type":"inlineCode","value":"loc","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"oHanctZMXl"},{"type":"text","value":" and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dHZOpz8fR9"},{"type":"inlineCode","value":"iloc","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"I0Op4iNPM9"},{"type":"text","value":" methods, however\nbecause we have named dimensions, we can directly specify them in\nour call.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"moJv7GS7u1"}],"key":"JMzrsk7G0O"}],"key":"xnmWYwCqsj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# We'll drop a subset of timepoints for visualization\nda = da.sel(time=slice(-1, 3))","key":"mu7h5EUsFY"},{"type":"output","id":"ho8d2w7UkiMHJsJiepM_3","data":[],"key":"iw0C7inzbt"}],"key":"o7N6YzpqyU"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Now let’s calculate the average across all epochs for each electrode/time point.\nThis is a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yh3e3To9yl"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"reduction","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RBkPBUzZH5"}],"key":"y8fh0xXniV"},{"type":"text","value":" of our data array, in that it reduces the number of dimensions.\nXarray has many of the same statistical methods that NumPy does. An interesting\ntwist is that you can specify named dimensions instead of simply an ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"luwsMETwv7"},{"type":"inlineCode","value":"axis=\u003cinteger\u003e","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"biLN7fxJjs"},{"type":"text","value":"\nargument. In addition, we’ll choose the colors that we’ll use for cycling through\nour channels - because we can quickly reference the channels axis by name, we don’t\nneed to remember which axis corresponds to channels.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZQKTY9gAyJ"}],"key":"NhvGqzHFUs"}],"key":"QBsr1ldzgG"},{"type":"block","kind":"notebook-code","data":{"tags":["full_width"]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nn_channels = da['channel'].shape[0]\nax.set_prop_cycle(color=plt.cm.viridis(np.linspace(0, 1, n_channels)))\nda.mean(dim='epoch').plot.line(x='time', hue='channel')\nax.get_legend().remove()","visibility":"show","key":"kJTlJXbrmw"},{"type":"output","id":"CkTH63gSXfqNZIBafgsRM","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"d2a005471e8a3037ad4047456d195f42","path":"/build/d2a005471e8a3037ad4047456d195f42.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"mgI0AzE0Hy"}],"visibility":"show","key":"u59J73LKsO"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"It doesn’t look like much is going on...let’s see if we can clean it up a bit.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oLPJFK9Pif"}],"key":"p3isYqQ2ea"}],"key":"LRjaB8pARH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"De-meaning the data with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mpfOqpbHye"},{"type":"inlineCode","value":"da.where","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k1cFw5FP4c"}],"identifier":"de-meaning-the-data-with-da-where","label":"De-meaning the data with da.where","html_id":"de-meaning-the-data-with-da-where","implicit":true,"key":"Zauuv8gJDP"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"First off - we’ll subtract the “pre-baseline mean” from each trial.\nThis makes it easier to visualize how each channel’s activity ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vAnBR95clr"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"changed","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"c73ksYKGsM"}],"key":"vz1xOibEea"},{"type":"text","value":"\nat time == 0.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bcyRlQTwPX"}],"key":"gmDrsZio9y"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"To accomplish this we’ll use ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NH3IL9Z781"},{"type":"inlineCode","value":"da.where","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"a05GB8z0t9"},{"type":"text","value":". This takes some kind of\nboolean-style mask, does a bunch of clever projections according to the\nnames of coordinates, and returns the dataarray masked values removed\n(as ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"XNb2oFzimC"},{"type":"inlineCode","value":"NaN","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"r8Yyq2CcAF"},{"type":"text","value":"s) and other values unchanged. We can use this to calculate the\nmean of each channel / epoch ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ogPsZpXSWp"},{"type":"emphasis","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"only for the pre-baseline timepoints","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"u5Ri4YpvLZ"}],"key":"AKCsiD02uH"},{"type":"text","value":".","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"orxLqhAbUf"}],"key":"Pc28v1yydI"}],"key":"g1I18zKEK6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# This returns a version of the data array with NaNs where the query is False\n# The dimensions will intelligently broadcast \nprebaseline_mean = da.where(da.time \u003c 0).mean(dim='time')\nda_demeaned = da - prebaseline_mean","key":"pPrXAdXr1o"},{"type":"output","id":"ncCxTs9K0TQNE8fL-vZ6H","data":[],"key":"o0e6LK5OVF"}],"key":"kD4BrDvqFP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now we can visualize the de-baseline-meaned data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dOm4rNjhaO"}],"key":"WPVZ257e6C"}],"key":"AzHm4CY4AK"},{"type":"block","kind":"notebook-code","data":{"tags":["full_width"]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nax.set_prop_cycle(color=plt.cm.viridis(np.linspace(0, 1, da['channel'].shape[0])))\nda_demeaned.mean(dim='epoch').plot.line(x='time', hue='channel')\nax.get_legend().remove()","visibility":"show","key":"XjWJjXeDJq"},{"type":"output","id":"8xkSs_0RtWoTEJydShQxh","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"353af84f275a78ecad4d82e77d4e808b","path":"/build/353af84f275a78ecad4d82e77d4e808b.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"KcT5NI4Mbj"}],"visibility":"show","key":"m1FBQcrmIj"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Hmmm, there still doesn’t seem to be much going on (that channel down\nat the bottom looks noisy to me, rather than having a meaningful signal)\nso let’s transform this signal into something with a bit more SNR to it.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t7J2ypOrtI"}],"key":"tOQMH92kzz"}],"key":"XsBZn3f9eF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Extracting a more useful feature with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AGDC2j5WqK"},{"type":"inlineCode","value":"xr.apply_ufunc","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TSQUXvyrZT"}],"identifier":"extracting-a-more-useful-feature-with-xr-apply-ufunc","label":"Extracting a more useful feature with xr.apply_ufunc","html_id":"extracting-a-more-useful-feature-with-xr-apply-ufunc","implicit":true,"key":"QepmBAuVfo"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Without going into too much details on the neuroscience, iEEG data is\nparticularly useful because there is information about neuronal activity in\nthe higher frequency parts of the signal (AKA, parts of the electrical signal that\nchange very quickly, but have very low amplitude). To pull that out, we’ll do the following:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DNHLbpeIfP"}],"key":"TKnGKKNgPW"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"High-pass filter the signal, which will remove all the slow-moving components","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"bGfoK7qfKz"}],"key":"uIhGPc2NH6"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Calculate the ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"PMocoeGXMF"},{"type":"emphasis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"envelope","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"cjDzchIKHy"}],"key":"Toy2iKyQsE"},{"type":"text","value":" of the signal, which will tell us the power of\nhigh-frequency activity over time.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Ohtj5gxykK"}],"key":"yhzMhS6NB6"}],"key":"pznMTE1A2i"},{"type":"heading","depth":3,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"High-pass filtering the signal","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Ds3ckRiTU7"}],"identifier":"high-pass-filtering-the-signal","label":"High-pass filtering the signal","html_id":"high-pass-filtering-the-signal","implicit":true,"key":"h1L8nizCnU"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"MNE has a lot of nice functions for filtering a timeseries. Most of these\noperate on numpy arrays instead of MNE objects. We’ll use\nxarray’s ","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"kMUuxSpLya"},{"type":"inlineCode","value":"apply_ufunc","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"KA4OZyztXZ"},{"type":"text","value":" function to simply map that function onto our dataarray.\nxarray should keep track of the metadata (e.g. coordinates etc) and output a\nnew DataArray with updated values.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"xftHmaGpcw"}],"key":"jYZTa1qTcv"}],"key":"sQLCx2dJSa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"flow = 80\nfhigh = 140\nda_lowpass = xr.apply_ufunc(\n    mne.filter.filter_data, da,\n   kwargs=dict(\n       sfreq=da.sfreq,\n       l_freq=flow,\n       h_freq=fhigh,\n   )\n)","key":"ORvshcM7GR"},{"type":"output","id":"wVUpFQaKgvRHd1BaNVcU2","data":[{"name":"stdout","output_type":"stream","text":"Setting up band-pass filter from 80 - 1.4e+02 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 80.00\n- Lower transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 70.00 Hz)\n- Upper passband edge: 140.00 Hz\n- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 145.00 Hz)\n- Filter length: 99 samples (0.330 sec)\n\n"}],"key":"EisseeiVAb"}],"key":"PKCRREBo1y"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Visualizing our data, we can see all the slower fluctuations (e.g. long arcs over time)\nare gone.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VM04GT2hA4"}],"key":"zU14RSFXgm"}],"key":"aG0i2WFZN3"},{"type":"block","kind":"notebook-code","data":{"tags":["full_width"]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nda_lowpass.mean(dim='epoch').plot.line(x='time')\nax.get_legend().remove()","visibility":"show","key":"HVKdGf3lPi"},{"type":"output","id":"oQv6AHqUAyABiyzYj95vv","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"8d4f3353e4f30638468ea9b2683d3bb4","path":"/build/8d4f3353e4f30638468ea9b2683d3bb4.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"OFWmrJUDTj"}],"visibility":"show","key":"BgtUx1bqDi"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Calculate the envelope of this signal with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Mdt3FMhPQR"},{"type":"inlineCode","value":"da.groupby","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ejqiQm6PHF"}],"identifier":"calculate-the-envelope-of-this-signal-with-da-groupby","label":"Calculate the envelope of this signal with da.groupby","html_id":"calculate-the-envelope-of-this-signal-with-da-groupby","implicit":true,"key":"UIddmIHn5c"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Next, we’ll calculate the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hqc8OMa8nP"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"envelope","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fOQIxVu6wv"}],"key":"Dtfc0E9AGT"},{"type":"text","value":" of the high-pass-filtered data. This is roughly\nthe ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dufBxmTSHJ"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"power","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"B6Gz7eVZXy"}],"key":"IUtsR4ulgD"},{"type":"text","value":" that is present in these high frequencies over time. We do so by using\nsomething called a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qRnMToTEJH"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"hilbert transform","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DVzP0H4On2"}],"key":"fbSMMf9DL3"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"olLy0jCNci"}],"key":"PffrEzoeBi"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"MNE also has a function for applying Hilbert transforms to data, but it has a weird quirk\nthat expects the data to be of a particular shape. We can work around this by using our\nDataArray’s ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ymVP3A2xSF"},{"type":"inlineCode","value":"groupby","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"b9Jhg5fEJm"},{"type":"text","value":" method. This works similar to ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Mdclh6RSxg"},{"type":"inlineCode","value":"DataFrame.groupby","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"feIHwc5i70"},{"type":"text","value":" - we’ll iterate\nthrough each channel, which will return a DataArray with shape ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rI4OEAZGeJ"},{"type":"inlineCode","value":"epochs x timepoints","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"KRMN6eStNl"},{"type":"text","value":".\nWe can then calculate the Hilbert transform in each and re-combine into the original shape.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FulpisdzjF"}],"key":"L04bKyfkct"}],"key":"UHvG4ns6uF"},{"type":"block","kind":"notebook-content","data":{"tags":["popout"]},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PLDL2phKoS"}],"key":"mFLeY49xCS"},{"type":"text","value":": This can be an expensive operation depending on the number of channels/epochs and\nthe length of each trial. This might be a good place to insert paralellization via Dask.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M2No8jDUbH"}],"key":"cNjwlRVWkp"}],"visibility":"show","key":"OgpemIwjd6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def hilbert_2d(array):\n    \"\"\"Perform a Hilbert transforms on an (n_channels, n_times) array.\"\"\"\n    for ii, channel in enumerate(array):\n        array[ii] = mne.filter._my_hilbert(channel, envelope=True)\n    return array\n\nda_hf_power = da_lowpass.groupby(da.coords['epoch']).apply(hilbert_2d)","key":"IfH2luDsqz"},{"type":"output","id":"r-MV7fQBWdYa8OeFrKpxV","data":[],"key":"B97fD3NLgp"}],"key":"rxfKiRUAl9"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The output dataarray should be the exact same shape, because we haven’t done any dimensional reductions.\nIf we take a look at the resulting data, we can see what seems to be more structure in there:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"clPBqbpGzA"}],"key":"fSb8EmFuRp"}],"key":"ZSqLDnQQvu"},{"type":"block","kind":"notebook-code","data":{"tags":["full_width"]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nda_hf_power.mean(dim='epoch').plot.line(x='time', hue='channel')\nax.get_legend().remove()","visibility":"show","key":"SyKqzEIsje"},{"type":"output","id":"xdMQjTYOwtdikVgzTn1GJ","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"bd0b6ea1aadfee7a494630159662ad6b","path":"/build/bd0b6ea1aadfee7a494630159662ad6b.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"yJ8WJY0WmX"}],"visibility":"show","key":"aJ1s3kI68K"},{"type":"block","kind":"notebook-content","data":{"toc-hr-collapsed":false},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Cleaning up our HFA data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CFmPYmQnMH"}],"identifier":"cleaning-up-our-hfa-data","label":"Cleaning up our HFA data","html_id":"cleaning-up-our-hfa-data","implicit":true,"key":"XpLlR3OuyW"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Next let’s clean up this high-frequency activity (HFA) data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WbiYwjEJM9"}],"key":"XebdTPQmF7"}],"key":"rF3JTbPuID"},{"type":"block","kind":"notebook-content","data":{"toc-hr-collapsed":false},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Z-scoring our array","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wbVRYtffnj"}],"identifier":"z-scoring-our-array","label":"Z-scoring our array","html_id":"z-scoring-our-array","implicit":true,"key":"kMPqD98hEp"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Instead of simple de-meaning\nthe data like before, we’ll ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nvrazP96nh"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"re-scale","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cVj5dlYGAZ"}],"key":"Qj9AfJ7bqv"},{"type":"text","value":" our data using the same baseline timepoints.\nWhat we’d like to do is the following:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FUfQ16yrct"}],"key":"IUJoHGbfvS"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Calculate the mean and standard deviation across trials of all pre-baseline data values, per channel","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ezG3lke3bT"}],"key":"N9KcoApjUl"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Z-score each channel using this mean and standard deviation","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"QEfBQwDgLJ"}],"key":"dhZszupVeY"}],"key":"fClZU2tPtM"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Once again we’ll use the groupby / apply combination to apply our function to subsets\nof the data.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"xZ8hcRJogI"}],"key":"o2KCCANfmU"}],"key":"g7caOfHdlp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# For each channel, apply a z-score that uses the mean/std of pre-baseline activity for all trials\ndef z_score(activity):\n    \"\"\"Take a DataArray and apply a z-score using the baseline\"\"\"\n    baseline = activity.where(activity.time \u003c -.1 )\n    return (activity - np.nanmean(baseline)) / np.nanstd(baseline)\n\nda_hf_zscored = da_hf_power.groupby('channel').apply(z_score)","key":"etJO6GvBLi"},{"type":"output","id":"nUpuEjatlG455RQ_uwAf3","data":[],"key":"t8xxLbZNEX"}],"key":"JfCfju7QOz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Taking a look at the result, we can see a much cleaner separation of activity for\nsome of the channels after ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sXnFJfxVTh"},{"type":"inlineCode","value":"time==0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l25VfusrMG"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GL7uWSRpXa"}],"key":"m85QvUGGdt"}],"key":"CTuYCZcNUD"},{"type":"block","kind":"notebook-code","data":{"tags":["full_width"]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nda_hf_zscored.mean(dim='epoch').plot.line(x='time', hue='channel')\nax.get_legend().remove()","visibility":"show","key":"WbRiCKY5O9"},{"type":"output","id":"IxKFNSfPdV_jnvUIbyxAj","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"6fa8536695567fa2cfa95d3ab343e1a2","path":"/build/6fa8536695567fa2cfa95d3ab343e1a2.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"dNXgdgonF0"}],"visibility":"show","key":"SPJdkDMmKg"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Smoothing our HFA data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mSoZbkupf6"}],"identifier":"smoothing-our-hfa-data","label":"Smoothing our HFA data","html_id":"smoothing-our-hfa-data","implicit":true,"key":"MyAaF6oQm0"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Finally, let’s smooth this HFA so it has less jitter to it, and pick a smaller window that\nremoves some of the filtering artifacts at the edges.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Dnzt3ipK6M"}],"key":"luokveaAhi"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"We’ll use the same ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"v8BFEIjEuO"},{"type":"inlineCode","value":"filter_data","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"DHNPKXoLZK"},{"type":"text","value":" function as before, but this time\napplied with the ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"YJNVLq5rg9"},{"type":"inlineCode","value":".groupby","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"dhimbMsZc7"},{"type":"text","value":" and ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lWR71BSwcR"},{"type":"inlineCode","value":".apply","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ut4UTKobZk"},{"type":"text","value":" combination to show two ways\nof accomplishing the same thing. We’ll also use ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"VsNkgIhxSm"},{"type":"inlineCode","value":".sel","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"p8E2sbpes2"},{"type":"text","value":" to pick a subset\nof time for visualization","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ieh7X07Wvw"}],"key":"rAzf438daZ"}],"key":"Gkn7H0BRZs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"da_hf_zscored_lowpass = da_hf_zscored.groupby('epoch').apply(\n    mne.filter.filter_data,\n    sfreq=da.sfreq,\n    l_freq=None,\n    h_freq=10,\n    verbose=False\n)","key":"KoikVtGgg1"},{"type":"output","id":"K9pa1kp26GFdnjq_eeKah","data":[],"key":"efnjJA0qbZ"}],"key":"vfmP8nFim1"},{"type":"block","kind":"notebook-content","data":{"tags":["popout"]},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Note that quickly selecting a subset of timepoints if we used numpy is much more verbose. Here’s\na quick comparison:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lRWC0iIr3b"}],"key":"iPqgxMzuJH"},{"type":"code","lang":"python","value":"# Numpy alone\nmask_time = (times \u003e -.8) * (times \u003c 2.8)\nepoch_dim = 0\nda_hf_zscored_lowpass[..., mask_time].mean(epoch_dim)\n\n# xarray\nda_hf_zscored_lowpass.sel(time=slice(-.8, 2.8)).mean(dim='epoch')","position":{"start":{"line":4,"column":1},"end":{"line":12,"column":1}},"key":"yucjP0aKg6"}],"visibility":"show","key":"EK6DvfAbfp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\nda_hf_zscored_lowpass.mean(dim='epoch').sel(time=slice(-.8, 2.8)).plot.line(x='time', hue='channel')\nax.get_legend().remove()","key":"EyglKCUowi"},{"type":"output","id":"3Og4HQrh2-w712QsQxLRf","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"a1097f62a3a45fd41be89555a8d5333c","path":"/build/a1097f62a3a45fd41be89555a8d5333c.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 1 Axes\u003e","content_type":"text/plain"}}}],"key":"OiMxj5NQsF"}],"key":"Cyt4QglC4o"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now we can see there are clearly some channels that become active just after ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nnGagW4tyX"},{"type":"inlineCode","value":"t==0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bZ1f2sEGaP"},{"type":"text","value":".\nWe can reduce our dataarray to a single dimension of “mean post-baseline activity in each channel”\nand convert it to a DataFrame for further processing:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U5Doyw0RkI"}],"key":"xHOXhyUrLK"}],"key":"FyHJ04TTVn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Find the channel with the most activity by first converting to a dataframe\ntotal_activity = da_hf_zscored_lowpass.sel(time=slice(0, 2)).mean(dim=['epoch', 'time'])\ntotal_activity = total_activity.to_dataframe()\ntotal_activity.head()","key":"XgCUQm9DC7"},{"type":"output","id":"wucP5SpZgcWRio9xW-_RU","data":[{"output_type":"execute_result","execution_count":35,"metadata":{},"data":{"text/html":{"content":"\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eSample dataset\u003c/th\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003echannel\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003ech_0\u003c/th\u003e\n      \u003ctd\u003e0.011101\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003ech_1\u003c/th\u003e\n      \u003ctd\u003e0.012152\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003ech_2\u003c/th\u003e\n      \u003ctd\u003e0.051911\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003ech_3\u003c/th\u003e\n      \u003ctd\u003e0.176188\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003ech_4\u003c/th\u003e\n      \u003ctd\u003e0.246021\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e","content_type":"text/html"},"text/plain":{"content":"         Sample dataset\nchannel                \nch_0           0.011101\nch_1           0.012152\nch_2           0.051911\nch_3           0.176188\nch_4           0.246021","content_type":"text/plain"}}}],"key":"KYie6nEZmS"}],"key":"GkwYmKUdqJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s grab the channel with maximal activation to look into a bit further.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fxzzig47qQ"}],"key":"ao3pgx7cUV"}],"key":"y5JhE7FQRx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"max_chan = total_activity.squeeze().sort_values(ascending=False).index[0]","key":"xuOObdDVvU"},{"type":"output","id":"Ebq8YiGUMpvAlUe7g2AvQ","data":[],"key":"fjzxUc4LwY"}],"key":"xb6Pk5NXsE"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Time frequency analysis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RNZYFhtTUg"}],"identifier":"time-frequency-analysis","label":"Time frequency analysis","html_id":"time-frequency-analysis","implicit":true,"key":"sjLxb5bWq9"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"As a final step, let’s ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hLBFAb7Op2"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"expand","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"uNX0KcM2jB"}],"key":"P4NFI0N7JG"},{"type":"text","value":" our DataArray and add another dimension.\nIn the above steps we specifically focused on high-frequency activity. A more\ncommon approach is to first create a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Esg1pxU0v7"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"spectrogram","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UAkUEs9so4"}],"key":"pLF9RMsTVW"},{"type":"text","value":" of your data to see activity\nacross many frequencies.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BCfTDAqQit"}],"key":"aUi0pMSm82"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"To do this, we’ll use another MNE function for creating a ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"TFwdMaCyjH"},{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Time-Frequency Representation","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ZCsn5KFWWR"}],"key":"GpkgLZ7HQ2"},{"type":"text","value":"\nor TFR. We’ll define a range of frequencies, and apply MNE’s function ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"rvMPHrqNvn"},{"type":"emphasis","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"directly on our DataArray","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"jKjKh8MtQJ"}],"key":"qiTYpjdkpv"},{"type":"text","value":".\nThis will return a NumPy array with the filtered values.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ipH5MgTUmL"}],"key":"fev6FpVUEx"}],"key":"AC2nHBi2z6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"frequencies = [2**ii for ii in np.arange(2, 9, .5)]\ntfr = mne.time_frequency.tfr_array_morlet(\n    da,\n    sfreq=da.sfreq,\n    freqs=frequencies,\n    n_cycles=4,\n)\n\n# Take the absolute value to throw out the non-real parts of the numbers\ntfr = np.abs(tfr)\ntfr[:2, :2, :2, :2]","key":"G7cA0piALU"},{"type":"output","id":"pSL4aXojfJqRAlj7N4cl0","data":[{"output_type":"execute_result","execution_count":37,"metadata":{},"data":{"text/plain":{"content":"array([[[[160.04103045, 160.38413909],\n         [171.73704543, 175.09249553]],\n\n        [[283.28699104, 285.21855726],\n         [241.65630528, 245.77098295]]],\n\n\n       [[[ 93.99546124,  94.4406537 ],\n         [ 78.02050045,  79.15324341]],\n\n        [[ 47.85148993,  49.90845151],\n         [ 53.97221461,  54.55793674]]]])","content_type":"text/plain"}}}],"key":"woyhoQ4XJ0"}],"key":"a0t6LyMfjw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Convert this data into a DataArray with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oQ5iIvEAu4"},{"type":"inlineCode","value":".expand_dims","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N9s2CLuv9P"}],"identifier":"convert-this-data-into-a-dataarray-with-expand-dims","label":"Convert this data into a DataArray with .expand_dims","html_id":"convert-this-data-into-a-dataarray-with-expand-dims","implicit":true,"key":"xV0QivYClO"}],"key":"k11IScku1p"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Next, we’ll convert this into a DataArray by using the metadata from our original\nDataArray. We can use the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Akd5CxzxFd"},{"type":"inlineCode","value":"expand_dims","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I3cGm4pFjY"},{"type":"text","value":" method to create a new dimension for our DataArray.\nWe’ll use this to store frequency information.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"F7QvqSm11h"}],"key":"nQXfI4KlL7"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"We’ll then reshape our new DataArray so that it matches the output of the MNE function,\nand use the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LWcZmtNom9"},{"type":"inlineCode","value":"copy","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"OzoKrqrUby"},{"type":"text","value":" method to create a new DataArray. By supplying the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"pqaO0Wn6S1"},{"type":"inlineCode","value":"data=","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"HuXkWiYnDI"},{"type":"text","value":" argument\nto copy, we directly insert the new data inside the generated DataArray.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"F3ZWDPXa9l"}],"key":"EWRWVUSqm6"}],"key":"Bhhsqq3uLh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"da_tfr = (da\n    .expand_dims(frequency=frequencies)\n    .transpose('epoch', 'channel', 'frequency', 'time')\n    .copy(data=np.log(tfr))\n)","key":"pfq4Zu2evC"},{"type":"output","id":"vc6VRQHc5bqmmtyyZ3RxU","data":[],"key":"lX4rYa0wat"}],"key":"H4RI2hClI8"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can now visualize this time-frequency representation over time","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wSJZ5QS1EP"}],"key":"GvObLzmoQH"}],"key":"WOcBnUC0Hn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(15, 5))\n(da_tfr\n    .sel({'frequency': slice(None, 180), 'channel': max_chan})\n    .mean('epoch')\n    .plot.imshow(x='time', y='frequency')\n)","key":"af121LjLdX"},{"type":"output","id":"oMkkjabnqZSa0mAO993z7","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"3d6257be54ef134bc9b4e2ea4ab2d85d","path":"/build/3d6257be54ef134bc9b4e2ea4ab2d85d.png"},"text/plain":{"content":"\u003cFigure size 1080x360 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"YtxwJ1h87T"}],"key":"FCJdgA14rx"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Similar to our one-dimensional visualizations above, it can be hard to visualize\nrelative changes in activity over a baseline (particularly because the amplitude scales\ninversely with the frequency).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UIRQY61BIB"}],"key":"U7o3pMSmaQ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Let’s apply a re-scaling function to our data so that\nwe can see things more clearly. This time we’ll use MNE’s ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LxtLZLnVwz"},{"type":"inlineCode","value":"rescale","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Xq67ZQeBI9"},{"type":"text","value":" function, which\nacts similarly to our ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IJZN6LS6Z0"},{"type":"inlineCode","value":"zscore","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nd553BExak"},{"type":"text","value":" function above.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KwK7DclfFt"}],"key":"xNyLfqRYVQ"}],"key":"M6Ygv1csTb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"da_tfr_baselined = xr.apply_ufunc(\n    mne.baseline.rescale,\n    da_tfr,\n    kwargs={'times': da_tfr.coords['time'], 'baseline': (None, -.1), \"mode\": 'zscore'}\n)","key":"VasBD0VMtY"},{"type":"output","id":"aJve-p1hBG1T7FrrRbG_A","data":[{"name":"stdout","output_type":"stream","text":"Applying baseline correction (mode: zscore)\n"}],"key":"fYxqB8chLv"}],"key":"abzNerVU79"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"again, the result should be a DataArray, so we can directly visualize it:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fJa1ImKE7r"}],"key":"zudpwlpxtg"}],"key":"sPl2kICSCz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"(da_tfr_baselined\n    .sel({'frequency': slice(None, 180), 'channel': max_chan, 'time': slice(-.8, 2.5)})\n    .mean('epoch')\n    .plot.imshow(x='time', y='frequency')\n)","key":"wkamrvfqfD"},{"type":"output","id":"s7kbXzJNZ-mYjC4N0AMZl","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"0e4ee40776d84c7b267e77baf6850539","path":"/build/0e4ee40776d84c7b267e77baf6850539.png"},"text/plain":{"content":"\u003cFigure size 432x288 with 2 Axes\u003e","content_type":"text/plain"}}}],"key":"nQtzdbeWOH"}],"key":"CSi20IT9DM"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now we can see a clear increase in activity in the higher frequencies at ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UXjv9cHrne"},{"type":"inlineCode","value":"t==0","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fZCymPxHKu"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"anJkFx4XCU"}],"key":"vWyL3JRwJC"}],"key":"efcLqnan0e"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Combining the two with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NehfPuwZDi"},{"type":"inlineCode","value":"xr.merge","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hVFQhY8V9N"}],"identifier":"combining-the-two-with-xr-merge","label":"Combining the two with xr.merge","html_id":"combining-the-two-with-xr-merge","implicit":true,"key":"PIQZhRFbOe"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Finally, let’s combine these two DataArrays into one. We know that they\nshare much of the same metadata - the first is “Amplitude of High-Frequency Activity”\nand the second is “Time-frequency power”. We should be able to merge these\ninto a single xarray ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WOjO9dxffY"},{"type":"inlineCode","value":"DataSet","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"EVPhOUGHCK"},{"type":"text","value":", which will allow us to perform operations across\nboth by using their shared dimensions. DataSets are kind of like collections of\nDataArrays, with assumptions that the DataArrays share some metadata or coordinates.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zvrM8DMUlY"}],"key":"gapTzAVn5m"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"First, we’ll rename each DataArray so that we can merge them nicely. Then, we’ll simply\nuse the ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"R2ZqcopdvZ"},{"type":"inlineCode","value":"xr.merge","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"HlQhDFUcWd"},{"type":"text","value":" function, which tries to automatically figure out which dimensions are\nshared based on their names and coordinate values.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"joYLO0T5f4"}],"key":"aubQOWeW3D"}],"key":"HrAe9Q3vAg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"da_tfr_baselined.name = \"Time Frequency Representation\"\nda_hf_zscored_lowpass.name = \"Low-pass filtered HFA\"\nds = xr.merge([da_tfr_baselined, da_hf_zscored_lowpass])\nds","key":"kP8Vbj0EPL"},{"type":"output","id":"w-tE8YiV184kJf62625Sy","data":[{"output_type":"execute_result","execution_count":43,"metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"c7a589cf576f3a807805fd4c44fb5444","path":"/build/c7a589cf576f3a807805fd4c44fb5444.html"},"text/plain":{"content":"\u003cxarray.Dataset\u003e\nDimensions:                        (channel: 32, epoch: 29, frequency: 14, time: 1201)\nCoordinates:\n  * frequency                      (frequency) float64 4.0 5.657 ... 256.0 362.0\n  * time                           (time) float64 -1.0 -0.9967 ... 2.997 3.0\n  * channel                        (channel) \u003cU5 'ch_0' 'ch_1' ... 'ch_31'\n  * epoch                          (epoch) int64 0 1 2 3 4 5 ... 24 25 26 27 28\nData variables:\n    Time Frequency Representation  (epoch, channel, frequency, time) float64 -1.068 ... 1.231\n    Low-pass filtered HFA          (epoch, channel, time) float64 -0.5572 ... -0.7839","content_type":"text/plain"}}}],"key":"qoAZiddjeF"}],"key":"ApaOUbYrIs"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Since we’ve got a single dataset, we can grab subsets along each axis across both\nDataArrays at the same time. We’ll select a subset of channels, time, and frequency bands\nto visualize.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gM4gtDccbP"}],"key":"P3OjSQZpwQ"}],"key":"UGs2qwyNhH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ds_plt = ds.sel({'channel': max_chan, 'frequency': slice(10, 150), 'time': slice(-.5, 2)})","key":"Ime9P3RFTz"},{"type":"output","id":"_Jo3qJXU-dqUZuFPm46V2","data":[],"key":"lJjFHlPwcl"}],"key":"xo3R34uX1p"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Now, we’ll plot ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ol5Nw6JjUf"},{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"both","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dnnGuhaXOJ"}],"key":"P45I35CFFR"},{"type":"text","value":" the spectrogram and the HFA in the same Matplotlib figure. As you\ncan see, these plots contain somewhat redundant information. The top plot tells us that there is\na general increase in power for high-frequencies. The bottom plot gives us the average increase in\npower across the higher frequencies.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"S0AcquFiXX"}],"key":"EANoXOS0h4"}],"key":"Go2mfSGe02"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, (ax_tfr, ax_hfa) = plt.subplots(2, 1, figsize=(15, 10))\nim = ds_plt['Time Frequency Representation'].mean('epoch').plot.imshow(x='time', y='frequency',\n                                                                       ax=ax_tfr)\n\nds_plt['Low-pass filtered HFA'].mean('epoch').plot.line(x='time', ax=ax_hfa)","key":"O6jhhLmHVI"},{"type":"output","id":"o2guiLsN-cM7beMGrvSRK","data":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"image/png":{"content_type":"image/png","hash":"f08d3a3e82c20477112b56b792308c6f","path":"/build/f08d3a3e82c20477112b56b792308c6f.png"},"text/plain":{"content":"\u003cFigure size 1080x720 with 3 Axes\u003e","content_type":"text/plain"}}}],"key":"zCU3TBi7Q7"}],"key":"kPayLC1khw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Wrapping up","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZvxNFNnoGx"}],"identifier":"wrapping-up","label":"Wrapping up","html_id":"wrapping-up","implicit":true,"key":"rXRSDNt3Eu"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In all, I was pretty happy with what you can do using xarray’s ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"i08kff5Ffy"},{"type":"inlineCode","value":"DataArray","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"OIQqk0Z2qg"},{"type":"text","value":" structure.\nIt’s pretty nice to be able to refer to axes by their names, and to make more intelligent\nselection / slicing operations using their coordinate values. Moreover, this post is just\nscratching the surface for how to use this information in a way that speeds up the exploration\nand analysis post.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UWrf2R7Bdd"}],"key":"FH2LS2TsgB"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"For example, we might have sped-up some feature extraction steps by using\na distributed processing framework like ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"jbSdcmzrKE"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Dask","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Y7Rer1Lnu3"}],"key":"eJJsqTFbsj"},{"type":"text","value":" in the operations above. Dask integrates nicely\nwith xarray, and offers a lot of interesting opportunities to parallelize interactive computation.\nI’ll explore that in another blog post.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"jdQDj5Yl4o"}],"key":"Xda86mGO66"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Finally - the goal of this post has largely been to learn a bit more about xarray. This means I might\nbe totally mis-using functionality, or missing something that would have made the above process much\neasier. If anybody has tips or thoughts on the code above, please do reach out!","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"L8JHdWCBGU"}],"key":"MuN05hPfmF"}],"key":"es7XvYIivs"}],"key":"T6AIFaaZzu"},"references":{"cite":{"order":["Holdgraf_2017"],"data":{"Holdgraf_2017":{"label":"Holdgraf_2017","enumerator":"1","doi":"10.3389/fnsys.2017.00061","html":"Holdgraf, C. R., Rieger, J. W., Micheli, C., Martin, S., Knight, R. T., \u0026 Theunissen, F. E. (2017). Encoding and Decoding Models in Cognitive Electrophysiology. \u003ci\u003eFrontiers in Systems Neuroscience\u003c/i\u003e, \u003ci\u003e11\u003c/i\u003e. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.3389/fnsys.2017.00061\"\u003e10.3389/fnsys.2017.00061\u003c/a\u003e","url":"https://doi.org/10.3389/fnsys.2017.00061"}}}},"footer":{"navigation":{"prev":{"title":"What would Rust-style governance look like in Jupyter?","url":"/blog/2019/2019-10-13-rust-jupyter-governance","group":"2019"},"next":{"title":"What would Python-style governance look like in Jupyter?","url":"/blog/2019/2019-10-27-jupyter-governance-python","group":"2019"}}},"domain":"http://localhost:3000"},"project":{"abbreviations":{"LF":"The Linux Foundation","JF":"The Jupyter Foundation","JEC":"Jupyter Executive Council","JFB":"The Jupyter Foundation Board","SSC":"Software Steering Council","OSPO":"Open Source Program Office"},"title":"Welcome","thumbnail":"/build/social_banner-898e7688b7efa2d20951c06d8eac661c.png","authors":[{"id":"chris","nameParsed":{"literal":"Chris Holdgraf","given":"Chris","family":"Holdgraf"},"name":"Chris Holdgraf","orcid":"0000-0002-2391-0678","affiliations":["affiliations-myst-generated-uid-0","affiliations-myst-generated-uid-1"],"url":"https://chrisholdgraf.com","github":"choldgraf","twitter":"choldgraf"}],"github":"https://github.com/choldgraf/choldgraf.github.io","affiliations":[{"name":"2i2c","url":"https://2i2c.org","id":"affiliations-myst-generated-uid-0"},{"name":"Project Jupyter","url":"https://jupyter.org","id":"affiliations-myst-generated-uid-1"}],"id":"f84d70c6-7ee5-4bb9-9056-aa84134a33dd","references":{"ttw":{"url":"https://book.the-turing-way.org"}},"toc":[{"file":"index.md"},{"file":"about.md"},{"file":"projects.md"},{"file":"publications.md"},{"file":"talks.md"},{"children":[{"children":[{"pattern":"blog/2025/**{.ipynb,.md}"}],"title":"2025"},{"children":[{"pattern":"blog/2024/**{.ipynb,.md}"}],"title":"2024"},{"children":[{"pattern":"blog/2023/**{.ipynb,.md}"}],"title":"2023"},{"children":[{"pattern":"blog/2022/**{.ipynb,.md}"}],"title":"2022"},{"children":[{"pattern":"blog/2021/**{.ipynb,.md}"}],"title":"2021"},{"children":[{"pattern":"blog/2020/**{.ipynb,.md}"}],"title":"2020"},{"children":[{"pattern":"blog/2019/**{.ipynb,.md}"}],"title":"2019"},{"children":[{"pattern":"blog/2018/**{.ipynb,.md}"}],"title":"2018"},{"children":[{"pattern":"blog/2017/**{.ipynb,.md}"}],"title":"2017"},{"children":[{"pattern":"blog/2016/**{.ipynb,.md}"}],"title":"2016"},{"children":[{"pattern":"blog/2015/**{.ipynb,.md}"}],"title":"2015"}],"file":"blog.md"}],"exports":[],"bibliography":[],"index":"index","pages":[{"slug":"about","title":"About me","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects","title":"Projects","description":"","date":"","thumbnail":"/build/7d9a7172f87d448f4ed0d90adb92d4db.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"publications","title":"Publications","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"talks","title":"Talks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"blog","title":"Blog","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":2,"title":"2025"},{"slug":"blog.2025.fund-systems-not-developmend","title":"Why open source foundations try to fund systems, not development","description":"","date":"2025-05-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jec"],"level":3},{"slug":"blog.2025.jec","title":"Why I’m running for the Jupyter Executive Council","description":"","date":"2025-01-14","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.jupyter-org-structure","title":"The relationship between the Jupyter Executive Council, Software Steering Council, and Foundation","description":"","date":"2025-03-02","thumbnail":"/build/jupyter-foundation-s-5613751144a7be17163c803ddf9d9f88.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter"],"level":3},{"slug":"blog.2025.more-contributors","title":"Jupyter can align the needs of its community and its foundation by enabling contribution","description":"","date":"2025-03-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2025.os-support","title":"Ways the Jupyter Foundation could support open source projects","description":"","date":"2025-02-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"level":2,"title":"2024"},{"slug":"blog.2024.blog-list","title":"Better blog lists with the MyST AST","description":"","date":"2024-11-09","thumbnail":"/build/sandbox-demo-5068bf739b4ccebce4546af8550093ca.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"slug":"blog.2024.bluesky","title":"How I’m trying to use BlueSky without getting burned again","description":"Some quick thoughts on moving from Twitter/X to BlueSky and how I'll try to use social media after being burned once by Twitter.\n","date":"2024-11-22","thumbnail":"/build/bluesky-castles-8489cda764168c75083db0e9fb75af24.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","social media"],"level":3},{"slug":"blog.2024.mystmd-with-the-blog","title":"Re-building my blog with MySTMD","description":"","date":"2024-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2024.programmatic-myst-with-jupyter","title":"Generate MyST with Jupyter and insert it into content programmatically","description":"","date":"2024-11-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["myst","jupyter"],"level":3},{"level":2,"title":"2023"},{"slug":"blog.2023.ai-for-good","title":"A few random opportunities in AI for Social Good","description":"","date":"2023-10-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.fosdem","title":"Report from FOSDEM23: beautiful chaos in a conference","description":"","date":"2023-02-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2023.social-directive","title":"A Sphinx directive for social media embeds","description":"","date":"2023-02-15","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"slug":"blog.2023.sphinx-add-extensions","title":"Bundle extensions with your Sphinx theme","description":"","date":"2023-01-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2022"},{"slug":"blog.2022.cloud-services-academia","title":"Ask Twitter: Why don’t academic researchers use cloud services?","description":"","date":"2022-09-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cloud"],"level":3},{"slug":"blog.2022.github-2022","title":"GitHub year in review","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.install-github-from-pyproject","title":"Install dependencies from GitHub with pyproject.toml or requirements.txt","description":"","date":"2022-12-31","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["software development"],"level":3},{"slug":"blog.2022.jupyterlite-workshop","title":"Report from the JupyterLite workshop: WebAssembly is pretty cool","description":"","date":"2022-12-10","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","webassembly"],"level":3},{"slug":"blog.2022.matplotlib-remote-font","title":"Load and plot a remote font with Matplotlib","description":"","date":"2022-12-06","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["matplotlib"],"level":3},{"slug":"blog.2022.orcid-auto-update","title":"Automatically updating my publications page with ORCID and doi.org","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["scholarship","doi","orcid"],"level":3},{"slug":"blog.2022.phantom-workflows-pull-requests","title":"Fix phantom GitHub workflows in your ci-cd with protected branch rules","description":"","date":"2022-11-27","thumbnail":"/build/abdd690fd5af613c25b40bb16d6ca824.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["cicd","github actions"],"level":3},{"slug":"blog.2022.precommit-autoupdate","title":"Automatically update pre-commit hook versions","description":"","date":"2022-12-03","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","git"],"level":3},{"slug":"blog.2022.shell-split","title":"subprocess.run can execute shell commands directly","description":"","date":"2022-11-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["shell","python"],"level":3},{"slug":"blog.2022.sphinx-custom-crossrefs","title":"Custom roles and domains in Sphinx with one line","description":"","date":"2022-11-21","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","scholarship","myst"],"level":3},{"slug":"blog.2022.sphinx-redirects-folder","title":"Automatically redirect folders in Sphinx websites","description":"","date":"2022-11-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2022.sphinx-update-config","title":"How to update Sphinx options during the build","description":"","date":"2022-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx"],"level":3},{"level":2,"title":"2021"},{"slug":"blog.2021.2021-12-18-hybrid-tutorial-prerecord","title":"Serving in two roles at once via pre-recorded tutorials","description":"","date":"2021-12-17","thumbnail":"/build/9c5f30a4a04a0ddea887b8cfbfca92ce.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["teaching"],"level":3},{"level":2,"title":"2020"},{"slug":"blog.2020.2020-01-22-rst-thoughts","title":"What do people think about rST?","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"slug":"blog.2020.organizations-help-oss-guide","title":"Contributing to open source: A short guide for organizations","description":"","date":"2020-11-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","sustainability"],"level":3},{"slug":"blog.2020.sphinx-blogging","title":"A new blog with Sphinx","description":"","date":"2020-10-10","thumbnail":"/build/sphinx-logo-5a4316ee72d502cc4b3cd0fa8e202e6c.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["sphinx","blogging","jupyter"],"level":3},{"slug":"blog.2020.sphinx-design-timeline","title":"Build a simple timeline with sphinx-design","description":"","date":"2020-01-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["markup","documentation"],"level":3},{"level":2,"title":"2019"},{"slug":"blog.2019.2019-01-29-three-things-circleci","title":"Three things I love about CircleCI","description":"","date":"2019-01-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["CICD","dev ops","software development"],"level":3},{"slug":"blog.2019.2019-03-16-jupyter-dev","title":"Thoughts from the Jupyter team meeting 2019","description":"","date":"2019-03-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["jupyter","community"],"level":3},{"slug":"blog.2019.2019-06-25-a-few-talks","title":"A few recent talks","description":"","date":"2019-06-25","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["talks"],"level":3},{"slug":"blog.2019.2019-10-11-automating-jb","title":"Automating Jupyter Book deployments with CI/CD","description":"","date":"2019-10-11","thumbnail":"/build/jb-auto-build-659c4aa53cce6935f7836772628b2ac9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["infrastructure"],"level":3},{"slug":"blog.2019.2019-10-13-rust-jupyter-governance","title":"What would Rust-style governance look like in Jupyter?","description":"","date":"2019-10-13","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance"],"level":3},{"slug":"blog.2019.2019-10-22-xarray-neuro","title":"Analyzing intracranial electrophysiology data with xarray","description":"","date":"2019-10-22","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["analysis","neuroscience","xarray","open source"],"level":3},{"slug":"blog.2019.2019-10-27-jupyter-governance-python","title":"What would Python-style governance look like in Jupyter?","description":"","date":"2019-10-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["governance","open source"],"level":3},{"slug":"blog.2019.2019-11-11-ipynb-pandoc","title":"Testing Pandoc and Jupyter Notebooks","description":"","date":"2019-11-11","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","pandoc","nbconvert"],"level":3},{"level":2,"title":"2018"},{"slug":"blog.2018.circlci-github","title":"Automatically mirror a github repository with CircleCI","description":"","date":"2018-12-18","thumbnail":"/build/circleci-mirror-depl-74eb51b2629d93b8d1c9bfeb51af3698.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity","CICD"],"level":3},{"slug":"blog.2018.circle-docs","title":"Using CircleCI to preview documentation in Pull Requests","description":"","date":"2018-10-16","thumbnail":"/build/sphinx-circle-logos-7fe72c2aaaa270a75de78ff9ca722b45.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["documentation","sphinx"],"level":3},{"slug":"blog.2018.conferences-summer-2018","title":"Summer conference report back","description":"","date":"2018-08-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","conferences","communities","jupyter"],"level":3},{"slug":"blog.2018.devopsdays-sv-2018","title":"An academic scientist goes to DevOps Days","description":"","date":"2018-05-18","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","devops","jupyterhub","teams"],"level":3},{"slug":"blog.2018.free-labor-partners","title":"Open communities need to be partners, not sources of free labor","description":"","date":"2018-12-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open communities","open culture","sustainability"],"level":3},{"slug":"blog.2018.jekyllmarkdown","title":"Blogging with Jupyter Notebooks and Jekyll using nbconvert templates","description":"","date":"2018-05-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","jekyll"],"level":3},{"slug":"blog.2018.kinds-of-openness","title":"How do projects signal how “open” they are?","description":"","date":"2018-10-26","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["open source","governance","community"],"level":3},{"slug":"blog.2018.makeitpop","title":"Introducing makeitpop, a tool to perceptually warp your data!\"","description":"","date":"2018-06-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python colormaps"],"level":3},{"slug":"blog.2018.my-workflow","title":"My weekly workflow","description":"","date":"2018-10-26","thumbnail":"/build/trello-board-project-77ef3950d27357e7a97fc93d2fe1e30f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["productivity"],"level":3},{"slug":"blog.2018.rust-governance","title":"I like Rust’s governance structure","description":"","date":"2018-10-18","thumbnail":"/build/2018-10-19-rust_logo-2a04f3b729ee03dfd25f52496d4576f3.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","governance","community"],"level":3},{"slug":"blog.2018.sphinx-copy-buttons","title":"Adding copy buttons to code blocks in Sphinx","description":"","date":"2018-07-05","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","blogging","sphinx","documentation"],"level":3},{"level":2,"title":"2017"},{"slug":"blog.2017.2017-01-04-matplotlib-cycles","title":"Matplotlib Cyclers are Great","description":"","date":"2017-01-04","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations"],"level":3},{"slug":"blog.2017.2017-03-16-dates-in-python","title":"Dates in python","description":"","date":"2017-03-16","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"slug":"blog.2017.2017-11-02-dates-multiple-plots","title":"Combining dates with analysis visualization in python","description":"","date":"2017-11-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science"],"level":3},{"level":2,"title":"2016"},{"slug":"blog.2016.2016-07-02-fft-time","title":"The beauty of computational efficiency","description":"","date":"2016-07-02","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","computation","efficiency","fft"],"level":3},{"slug":"blog.2016.2016-07-08-voting-randomness","title":"Could Brexit have happened by chance?","description":"","date":"2016-07-08","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","voting","statistics","computation","fft"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016","title":"5 things I learned at SciPy","description":"","date":"2016-11-01","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","programming","conferences"],"level":3},{"slug":"blog.2016.2016-11-01-5-things-scipy-2016-1","title":"1. Scientific conferences can be fun","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"slug":"blog.2016.2016-11-30-funnel-plots","title":"Visualizing publication bias","description":"","date":"2016-11-30","thumbnail":"/build/funnel_plot_no_dists-19972fc44f9d3c2d95384c9da4a10562.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","funnel plots","open science","visualizations","simulations"],"level":3},{"slug":"blog.2016.2016-12-19-biorxiv-neuro","title":"The bleeding edge of publishing, Scraping publication amounts at biorxiv","description":"","date":"2016-12-19","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","web scraping","preprints"],"level":3},{"slug":"blog.2016.2016-12-23-christmas-ecog-plot","title":"Brainy Jingle Bells","description":"","date":"2016-12-23","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","open science","visualizations","brains","holidays"],"level":3},{"level":2,"title":"2015"},{"slug":"blog.2015.2015-05-27-coherence-correlation","title":"Coherence vs. Correlation - a simple simulation","description":"","date":"2015-05-27","thumbnail":"/build/eeg_coh-7a3ec59068b2ba221f0e4941450da5c9.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming","timeseries","correlation"],"level":3},{"slug":"blog.2015.2015-08-30-craigslist-scrape","title":"Scraping craigslist","description":"","date":"2015-08-30","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","programming"],"level":3},{"slug":"blog.2015.2015-09-27-craigslist-data-analysis","title":"Craigslist data analysis","description":"","date":"2015-09-27","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","scraping","data analysis","visualization"],"level":3},{"slug":"blog.2015.2015-10-29-nih-grant-analysis","title":"NIH grant analysis","description":"","date":"2015-10-29","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["python","statistics","visualization","grants"],"level":3}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-2671EB98.js";
import * as route0 from "/build/root-LMCDRB6W.js";
import * as route1 from "/build/routes/$-SJYMRUNJ.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>