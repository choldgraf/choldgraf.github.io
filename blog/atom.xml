<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>http://lernfunk.de/media/654321</id>
  <title>Predictably Noisy</title>
  <updated>2020-10-10T19:19:32.144925+00:00</updated>
  <link href="https://predictablynoisy.com"/>
  <link href="https://predictablynoisy.com/blog/atom.xml"/>
  <generator uri="https://ablog.readthedocs.org" version="0.10.10">ABlog</generator>
  <entry>
    <id>https://predictablynoisy.com/posts/2015/2015-05-27-coherence_correlation/</id>
    <title>Coherence correlation</title>
    <updated>2015-05-27T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;&lt;em&gt;Note - you can find the nbviewer of this post &lt;a class="reference external" href="https://github.com/choldgraf/write-ups/blob/master/neuro/coherence_correlation.ipynb"&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A big question that I’ve always wrestled with is the difference between correlation and coherence. Intuitively, I think of these two things as very similar to one another. Correlation is a way to determine the extent to which two variables covary (normalized to be between -1 and 1). Coherence is similar, but instead assesses “similarity” by looking at the similarity for two variables in frequency space, rather than time space.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2015/2015-05-27-coherence_correlation/" rel="alternate"/>
    <published>2015-05-27T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2015/2015-08-30-craigslist_scrape/</id>
    <title>Scraping craigslist</title>
    <updated>2015-08-30T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;In this notebook, I’ll show you how to make a simple query on Craigslist using some nifty python modules. You can take advantage of all the structure data that exists on webpages to collect interesting datasets.&lt;/p&gt;
&lt;p&gt;First we need to figure out how to submit a query to Craigslist. As with many websites, one way you can do this is simply by constructing the proper URL and sending it to Craigslist. Here’s a sample URL that is returned after manually typing in a search to Craigslist:&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2015/2015-08-30-craigslist_scrape/" rel="alternate"/>
    <published>2015-08-30T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2015/2015-09-27-craigslist_data_analysis/</id>
    <title>Craigslist data analysis</title>
    <updated>2015-09-27T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;In the &lt;a class="reference external" href="http://chrisholdgraf.com/querying-craigslist-with-python/"&gt;last post&lt;/a&gt; I showed how to use a simple python bot to scrape data from Criagslist. This is a quick follow-up to take a peek at the data.&lt;/p&gt;
&lt;p&gt;Note - data that you scrape from Craigslist is pretty limited. They tend to clear out old posts, and you can only scrape from recent posts anyway to avoid them blocking you.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2015/2015-09-27-craigslist_data_analysis/" rel="alternate"/>
    <published>2015-09-27T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2015/2015-10-29-nih_grant_analysis/</id>
    <title>NIH grant analysis</title>
    <updated>2015-10-29T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;As I’m entering the final years of graduate school, I’ve been applying for a few typical “pre-doc” fellowships. One of these is the NRSA, which is notorious for requiring you to wade through forests of beaurocratic documents (seriously, their “guidelines” for writing an NRSA are over 100 pages!). Doing so ends up taking a LOT of time.&lt;/p&gt;
&lt;p&gt;This got me wondering what kind of success rates these grants have in the first place. For those who haven’t gone through the process before, it’s a bit opaque:&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2015/2015-10-29-nih_grant_analysis/" rel="alternate"/>
    <published>2015-10-29T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-07-02-fft_time/</id>
    <title>The beauty of computational efficiency</title>
    <updated>2016-07-02T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;When we discuss “computational efficiency”, you often hear people throw around phrases like &lt;span class="math notranslate nohighlight"&gt;\(O(n^2)\)&lt;/span&gt; or &lt;span class="math notranslate nohighlight"&gt;\(O(nlogn)\)&lt;/span&gt;. We talk about them in the abstract, and it can be hard to appreciate what these distinctions mean and how important they are. So let’s take a quick look at what computational efficiency looks like in the context of a very famous algorithm: The Fourier Transform.&lt;/p&gt;
&lt;p&gt;Briefly, A Fourier Transform is used for uncovering the spectral information that is present in a signal. AKA, it tells us about oscillatory components in the signal, and has &lt;a class="reference external" href="http://dsp.stackexchange.com/questions/69/why-is-the-fourier-transform-so-important"&gt;a wide range&lt;/a&gt; of uses in communications, signal processing, and even neuroscience analysis.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-07-02-fft_time/" rel="alternate"/>
    <published>2016-07-02T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-07-08-voting_randomness/</id>
    <title>Could Brexit have happened by chance?</title>
    <updated>2016-07-08T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;As a scientist, watching the Brexit vote was a little bit painful. Though probably not for the reason you’re thinking. No, it wasn’t the politics that bothered me, but the method for making such an incredibly important decision. Let me explain…&lt;/p&gt;
&lt;p&gt;Scientists are a bit obsessed with the concept of error. In the context of collecting data and anaylzing it, this takes the form of our “confidence” in the results. If all the data say the same thing, then we are usually pretty confident in the overall message. If the data is more complicated than this (and it always is), then we need to define &lt;em&gt;how confident&lt;/em&gt; we are in our conclusions.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-07-08-voting_randomness/" rel="alternate"/>
    <published>2016-07-08T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-11-01-5_things_scipy_2016/</id>
    <title>5 things I learned at SciPy</title>
    <updated>2016-11-01T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;I’ve finally decompressed after my first go-around with Scipy. For those who haven’t heard of this conference before, Scipy is an annual meeting where members of scientific community get together to discuss their love of Python, scientific programming, and open science. It spans both academics and people from industry, making it a unique place in terms of how software interfaces with scientific research. (if you’re interested the full set of Scipy conferences, &lt;a class="reference external" href="http://conference.scipy.org/index.html"&gt;check out here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was an eye-opening experience that I learned a lot from, so here’s a quick recap of some things that I learned during my first rodeo.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-11-01-5_things_scipy_2016/" rel="alternate"/>
    <published>2016-11-01T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-11-30-funnel_plots/</id>
    <title>Visualizing publication bias</title>
    <updated>2016-11-30T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;&lt;strong&gt;This article is now interactive! Check out a live Binder instance &lt;a class="reference external" href="http://mybinder.org/repo/choldgraf/choldgraf.github.io/notebooks/notebooks/2016_11_30-funnel_plots.ipynb"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the next few months, I’ll try to take some time to talk about the things I learn as I make my way through this literature. While it’s easy to make one-off complaints to one another about how “science is broken” without really diving into the details, it’s important learn about &lt;em&gt;how&lt;/em&gt; it’s broken, or at least how we could assess something like this.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-11-30-funnel_plots/" rel="alternate"/>
    <published>2016-11-30T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-12-19-biorxiv_neuro/</id>
    <title>The bleeding edge of publishing, Scraping publication amounts at biorxiv</title>
    <updated>2016-12-19T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Per a recent request somebody posted on Twitter, I thought it’d be fun to write a quick scraper for the &lt;a class="reference external" href="http://biorxiv.org/"&gt;biorxiv&lt;/a&gt;, an excellent new tool for posting pre-prints of articles before they’re locked down with a publisher embargo.&lt;/p&gt;
&lt;p&gt;A big benefit of open science is the ability to use modern technologies (like web scraping) to make new use of data that would originally be unavailable to the public. One simple example of this is information and metadata about published articles. While we’re not going to dive too deeply here, maybe this will serve as inspiration for somebody else interested in scraping the web.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-12-19-biorxiv_neuro/" rel="alternate"/>
    <published>2016-12-19T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2016/2016-12-23-christmas_ecog_plot/</id>
    <title>Brainy Jingle Bells</title>
    <updated>2016-12-23T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;This is a quick demo of how I created &lt;a class="reference external" href="https://www.youtube.com/watch?v=lZS4uaTBrh8"&gt;this video&lt;/a&gt;. Check it out below, or read on to see the code that made it!&lt;/p&gt;
&lt;p&gt;Here’s a quick viz to show off some brainy holiday spirit.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2016/2016-12-23-christmas_ecog_plot/" rel="alternate"/>
    <published>2016-12-23T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2017/2017-01-04-matplotlib_cycles/</id>
    <title>Matplotlib Cyclers are Great</title>
    <updated>2017-01-04T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Every now and then I come across a nifty feature in Matplotlib that I wish I’d known about earlier. The MPL documentation can be a beast to get through, and as a result you miss some cool stuff sometimes.&lt;/p&gt;
&lt;p&gt;This is a quick demo of one such feature: the &lt;strong&gt;cycler&lt;/strong&gt;.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2017/2017-01-04-matplotlib_cycles/" rel="alternate"/>
    <published>2017-01-04T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2017/2017-03-16-dates_in_python/</id>
    <title>Dates in python</title>
    <updated>2017-03-16T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;As a part of setting up the website for the &lt;a class="reference external" href="http://docathon.org"&gt;Docathon&lt;/a&gt; I’ve had to re-learn all of my date string formatting rules. It’s one of those little problems you don’t really think about - turning an arbitrary string into something structured like a date - until you’ve actually got to do it.&lt;/p&gt;
&lt;p&gt;There are a bunch of tools in python for using date-like objects, but it’s not always easy to figure out how these work. This post is just a couple of pieces of information I’ve picked up along the process.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2017/2017-03-16-dates_in_python/" rel="alternate"/>
    <published>2017-03-16T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2017/2017-11-02-dates_multiple_plots/</id>
    <title>Combining dates with analysis visualization in python</title>
    <updated>2017-11-02T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Sometimes you want to do two things:&lt;/p&gt;
&lt;p&gt;Plot a timeseries that handles datetimes in a clever way (e.g., with Pandas or Matplotlib)&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2017/2017-11-02-dates_multiple_plots/" rel="alternate"/>
    <published>2017-11-02T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2018/2018-06-04-makeitpop/</id>
    <title>Introducing _makeitpop_, a tool to perceptually warp your data!</title>
    <updated>2018-06-04T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;It should go without saying, but &lt;strong&gt;you should never do the stuff that you’re about to read about here&lt;/strong&gt;. Data is meant to speak for itself, and our visualizations should accurately reflect the data above all else.*&lt;/p&gt;
&lt;p&gt;When I was in graduate school, I tended to get on my soapbox and tell everybody
why they should &lt;a class="reference external" href="http://jakevdp.github.io/blog/2014/10/16/how-bad-is-your-colormap/"&gt;stop using Jet&lt;/a&gt;
and adopt a “perceptually-flat” colormap like &lt;a class="reference external" href="https://bids.github.io/colormap/"&gt;viridis, magma, or inferno&lt;/a&gt;.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2018/2018-06-04-makeitpop/" rel="alternate"/>
    <published>2018-06-04T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-01-29-three-things-circleci/</id>
    <title>Three things I love about CircleCI</title>
    <updated>2019-01-29T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;I recently had to beef up the continuous deployment of Jupyter Book, and used
it as an opportunity to learn a bit more about CircleCI’s features. It turns out,
they’re pretty cool! Here are a few of the things that I learned this time around.&lt;/p&gt;
&lt;p&gt;For those who aren’t familiar with CircleCI, it is a service that runs Continuous
Integration and Continuous Deployment (CI/CD) workflows for projects. This basically
means that they manage many kinds of infrastructure that can launch jobs that run
test suites, deploy applications, and test on many different environments.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-01-29-three-things-circleci/" rel="alternate"/>
    <published>2019-01-29T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-03-16-jupyter-dev/</id>
    <title>Thoughts from the Jupyter team meeting 2019</title>
    <updated>2019-03-30T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;I just got back from a week-long Jupyter team meeting that was somehow both
very tiring and energizing at the same time. In the spirit of openness, I’d
like to share some of my experience. While it’s still fresh in my mind,
here are a few takeaways that occurred to me throughout the week.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note that these are my personal (rough) impressions, but they shouldn’t be taken as a
statement from the project/community itself.&lt;/em&gt;&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-03-16-jupyter-dev/" rel="alternate"/>
    <published>2019-03-30T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-06-25-a-few-talks/</id>
    <title>A few recent talks</title>
    <updated>2019-06-25T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Lately I’ve given quite a number of talks about the Jupyter and Binder
ecosystems for various purposes. Before each of the talks, I make the
slides available at a public address in case others are interested in
following up with the material. For those who missed the talks (or the
subsequent tweets about them), here are a few of the more recent ones.&lt;/p&gt;
&lt;p&gt;A word of warning: there’s a lot of overlap between these talks - I’m not
crazy enough to re-invent the wheel each time I have to speak. However, maybe
folks will find some value in the different angles taken in each case.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-06-25-a-few-talks/" rel="alternate"/>
    <published>2019-06-25T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-10-11-automating-jb/</id>
    <title>Automating Jupyter Book deployments with CI/CD</title>
    <updated>2019-10-11T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Lately I’ve spent a lot of time trying to reduce the friction involved
in deploying Jupyter Book as well as contributing to the project.
Features are a great carrot, but ultimately getting engagement is also
about lowering barriers to entry and showing people a path forward.
Jupyter Book is a relatively straightforward project, but it involves
a few technical pieces that can be painful to use (thanks Jekyll).&lt;/p&gt;
&lt;p&gt;Recently I experimented with whether we can &lt;strong&gt;automate deploying a Jupyter Book online&lt;/strong&gt;.
Using continuous integration / deployment services seems like a natural place
to try this out. One can upload a barebones set of code to a GitHub repository,
then configure a build system to create a book and deploy it online from there.
This blog post is a place to keep track of the current state of affairs for this workflow.&lt;/p&gt;
&lt;img alt="auto build logos" src="../_images/jb-auto-build.png" /&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-10-11-automating-jb/" rel="alternate"/>
    <published>2019-10-11T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-10-13-rust-jupyter-governance/</id>
    <title>What would Rust-style governance look like in Jupyter?</title>
    <updated>2019-10-13T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;As I’ve written about before, I &lt;a class="reference external" href="https://predictablynoisy.com/rust-governance"&gt;like Rust’s governance structure&lt;/a&gt;.
I mean, who can’t get behind a community that
&lt;a class="reference external" href="https://www.rust-lang.org/governance"&gt;lists governance as a top-level page on its website&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Jupyter is currently in the middle of
&lt;a class="reference external" href="https://discourse.jupyter.org/t/governance-office-hours-meeting-minutes/1480/26"&gt;figuring out the next phase of its governance structure&lt;/a&gt;,
and so I have been thinking about
what this might look like. This post is a quick thought-experiment to explore what it’d mean
to port over Rust’s governance directly into the Jupyter community.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-10-13-rust-jupyter-governance/" rel="alternate"/>
    <published>2019-10-13T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-10-22-xarray-neuro/</id>
    <title>Analyzing intracranial electrophysiology data with xarray</title>
    <updated>2019-10-22T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Over the last few years, it has been exciting to see the xarray project evolve,
add new functionality, and mature. This post is an attempt at
giving xarray another visit to see how it could integrate into electrophysiology
workflows.&lt;/p&gt;
&lt;p&gt;It is common in neuroscience to ask individuals to perform a task over and over again. You record
the activity in the brain each time they perform the task (called an “epoch” or a “trial”).
Time is recorded relative to some &lt;em&gt;onset&lt;/em&gt; when the task begins. That is &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;t==0&lt;/span&gt;&lt;/code&gt;. The result
is usually a matrix of &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;epochs&lt;/span&gt; &lt;span class="pre"&gt;x&lt;/span&gt; &lt;span class="pre"&gt;channejupyls&lt;/span&gt; &lt;span class="pre"&gt;x&lt;/span&gt; &lt;span class="pre"&gt;time&lt;/span&gt;&lt;/code&gt;. You can do a lot of stuff with this
data, but our task in this paper is to detect changes in neural activity at trial onset (&lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;t==0&lt;/span&gt;&lt;/code&gt;).&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-10-22-xarray-neuro/" rel="alternate"/>
    <published>2019-10-22T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-10-27-jupyter-governance-python/</id>
    <title>What would Python-style governance look like in Jupyter?</title>
    <updated>2019-10-27T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;This is the second in a series of blog posts that explores what it’d look like to
directly port the governance model of other communities into the Jupyter project.
You can find the &lt;a class="reference external" href="https://predictablynoisy.com/rust-jupyter-governance"&gt;first post about Rust here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These posts are meant as a thought experiment rather than a proposal. Moreover,
all the usual caveats come with it, such as the
fact that I don’t know the Python governance
structure &lt;em&gt;that&lt;/em&gt; well, and I might totally
botch my characterization of it.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-10-27-jupyter-governance-python/" rel="alternate"/>
    <published>2019-10-27T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2019/2019-11-11-ipynb_pandoc/</id>
    <title>Testing Pandoc and Jupyter Notebooks</title>
    <updated>2019-11-11T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;For several months now, the universal &lt;a class="reference external" href="https://pandoc.org/"&gt;document converter pandoc&lt;/a&gt; has
had &lt;a class="reference external" href="https://pandoc.org/MANUAL.html#creating-jupyter-notebooks-with-pandoc"&gt;support for Jupyter Notebooks&lt;/a&gt;. This means that with a single call,
you can convert &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;.ipynb&lt;/span&gt;&lt;/code&gt; files to any of the output formats that Pandoc
supports (and vice-versa!). This post is a quick exploration of what this
looks like.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that for this post, we’re using Pandoc version 2.7.3&lt;/strong&gt;. Also, some of what’s below is hard
to interpret without actually opening the files that are created by Pandoc. For the sake
of this blog post, I’m going to stick with the raw text output here, though you can expand the
outputs if you wish, I recommend copy/pasting some of these commands on your own if you’d like to try.&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2019/2019-11-11-ipynb_pandoc/" rel="alternate"/>
    <published>2019-11-11T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2020/2020-01-22-rst-thoughts/</id>
    <title>What do people think about rST?</title>
    <updated>2020-01-22T00:00:00+00:00</updated>
    <content type="html">&lt;p&gt;Publishing computational narratives has always been a dream of the Jupyter Project,
and there is still a lot of work to be done in improving these use-cases. We’ve made
a lot of progress in providing open infrastructure for reproducible science with
&lt;a class="reference external" href="https://jupyterhub.readthedocs.io/en/stable/"&gt;JupyterHub&lt;/a&gt; and
&lt;a class="reference external" href="https://mybinder.org/"&gt;the Binder Project&lt;/a&gt;, but what about the documents themselves?
We’ve recently been working on tools like &lt;a class="reference external" href="https://jupyterbook.org"&gt;Jupyter Book&lt;/a&gt;,
which aim to improve the writing and publishing process with the Jupyter ecosystem.
This is hopefully the first post of a few that ask how we can best-improve the state
of publishing with Jupyter.&lt;/p&gt;
&lt;p&gt;Many of the ideas in this post have now made their way into a new flavor of markdown called &lt;a class="reference external" href="https://myst-parser.readthedocs.io"&gt;Markedly Structured Text&lt;/a&gt;, or MyST. It brings all of the features of rST into Markdown. Check it out!&lt;/p&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2020/2020-01-22-rst-thoughts/" rel="alternate"/>
    <published>2020-01-22T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://predictablynoisy.com/posts/2020/sphinx-blogging/</id>
    <title>A new blog with Sphinx</title>
    <updated>2020-10-10T00:00:00+00:00</updated>
    <author>
      <name>Chris Holdgraf</name>
    </author>
    <content type="html">&lt;p&gt;I recently re-wrote all of the infrastructure for my blog so that it now builds on top of the Sphinx ecosystem! This is a short post to describe the reasons for doing so, and a bit about the implementation.&lt;/p&gt;
&lt;p&gt;This is a great question. The answer to “should you re-work your blog to use a new SSG” is almost always “no, it’s a waste of your time”, but I think I had a few good reasons ;-)&lt;/p&gt;
&lt;img alt="https://www.sphinx-doc.org/en/master/_static/sphinxheader.png" class="bg-dark" src="https://www.sphinx-doc.org/en/master/_static/sphinxheader.png" /&gt;
</content>
    <link href="https://predictablynoisy.com/posts/2020/sphinx-blogging/" rel="alternate"/>
    <published>2020-10-10T00:00:00+00:00</published>
  </entry>
</feed>
